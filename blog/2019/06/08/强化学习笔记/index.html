<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="Hazza Cheng" />



<meta name="description" content="版权声明：本文原创，转载请留意文尾，如有侵权请留言，谢谢 引言 　　主要记录关于强化学习的一些笔记，强化学习主要分为基于动态规划的有模型学习和基于蒙特卡洛方法的免模型学习。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础（十二）- 强化学习笔记">
<meta property="og:url" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="零一人生">
<meta property="og:description" content="版权声明：本文原创，转载请留意文尾，如有侵权请留言，谢谢 引言 　　主要记录关于强化学习的一些笔记，强化学习主要分为基于动态规划的有模型学习和基于蒙特卡洛方法的免模型学习。">
<meta property="og:locale">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/11.png">
<meta property="og:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/12.png">
<meta property="article:published_time" content="2019-06-08T13:47:50.000Z">
<meta property="article:modified_time" content="2020-06-08T05:53:07.000Z">
<meta property="article:author" content="Hazza Cheng">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="DP">
<meta property="article:tag" content="Reinforcement Learning">
<meta property="article:tag" content="MDP">
<meta property="article:tag" content="K-armed bandit">
<meta property="article:tag" content="Exploration-Exploitation dilemma">
<meta property="article:tag" content="epsilon-Greedy">
<meta property="article:tag" content="Softmax">
<meta property="article:tag" content="policy iteration">
<meta property="article:tag" content="value iteration">
<meta property="article:tag" content="Monte Carlo Learning">
<meta property="article:tag" content="Temporal Difference Learning">
<meta property="article:tag" content="Sarsa">
<meta property="article:tag" content="Q-learning">
<meta property="article:tag" content="Imitation Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="零一人生" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.ico">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">



<link rel="stylesheet" href="/css/style.css">




<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>机器学习基础（十二）- 强化学习笔记 | 零一人生</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






<meta name="generator" content="Hexo 6.3.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/"></a></h1>
        </hgroup>

        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0">读书笔记</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:hazzacheng@gmail.com" title="Email"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa Github" target="_blank" rel="noopener" href="https://github.com/HazzaCheng" title="Github"></a>
                            
                                <a class="fa 知乎" target="_blank" rel="noopener" href="https://www.zhihu.com/people/hazzacheng" title="知乎"></a>
                            
                                <a class="fa 豆瓣" target="_blank" rel="noopener" href="https://www.douban.com/people/HazzaCheng/" title="豆瓣"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/A/" rel="tag">A*</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AGNES/" rel="tag">AGNES</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AQS/" rel="tag">AQS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AUC/" rel="tag">AUC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Abstract-Factory-Pattern/" rel="tag">Abstract Factory Pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Accumulating-Trace/" rel="tag">Accumulating Trace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Accuracy/" rel="tag">Accuracy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Acquisition-function/" rel="tag">Acquisition function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Action-Preference-Function/" rel="tag">Action Preference Function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Active-Learning/" rel="tag">Active Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Actor%E2%80%93Critic/" rel="tag">Actor–Critic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AdaBoost/" rel="tag">AdaBoost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Adjoint/" rel="tag">Adjoint</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Advantage-Function/" rel="tag">Advantage Function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Amdahl/" rel="tag">Amdahl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Append-only-Tree/" rel="tag">Append-only Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArrayDeque/" rel="tag">ArrayDeque</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Atomic/" rel="tag">Atomic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AutoML/" rel="tag">AutoML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/B-Tree/" rel="tag">B+ Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/B-Tree/" rel="tag">B-Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BFS/" rel="tag">BFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BFT/" rel="tag">BFT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BGD/" rel="tag">BGD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BO/" rel="tag">BO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BOHB/" rel="tag">BOHB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BP/" rel="tag">BP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BST/" rel="tag">BST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bagging/" rel="tag">Bagging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bandit-learning/" rel="tag">Bandit learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Barrier/" rel="tag">Barrier</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Baum-Welch/" rel="tag">Baum-Welch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayes-Classifiers/" rel="tag">Bayes Classifiers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayes-Rule/" rel="tag">Bayes Rule</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian-Estimation/" rel="tag">Bayesian Estimation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian-Linear-Regression/" rel="tag">Bayesian Linear Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian-Network/" rel="tag">Bayesian Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian-Statistical-Inference/" rel="tag">Bayesian Statistical Inference</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bellman-Expectation-Equation/" rel="tag">Bellman Expectation Equation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bellman-Optimal-Equation/" rel="tag">Bellman Optimal Equation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bellman-Ford/" rel="tag">Bellman-Ford</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bernoulli-Distribution/" rel="tag">Bernoulli Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bernoulli-Process/" rel="tag">Bernoulli Process</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bias-Variance-Decomposition/" rel="tag">Bias-Variance Decomposition</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bias-Variance-Dilemma/" rel="tag">Bias-Variance Dilemma</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Big-Data/" rel="tag">Big Data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BigTable/" rel="tag">BigTable</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Binomial-Distribution/" rel="tag">Binomial Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BlockingQueue/" rel="tag">BlockingQueue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Boosting/" rel="tag">Boosting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Boosting-Tree/" rel="tag">Boosting Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C-K-Equation/" rel="tag">C-K Equation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C4-5/" rel="tag">C4.5</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CAP/" rel="tag">CAP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CART/" rel="tag">CART</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CAS/" rel="tag">CAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CASH/" rel="tag">CASH</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CDF/" rel="tag">CDF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Calculus/" rel="tag">Calculus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Callable/" rel="tag">Callable</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Central-Limit-Theorem/" rel="tag">Central Limit Theorem</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chebyshev-s-Inequality/" rel="tag">Chebyshev&#39;s Inequality</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chi-Squared-Test/" rel="tag">Chi-Squared Test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chi-squared-distribution/" rel="tag">Chi-squared distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chubby/" rel="tag">Chubby</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ClassTag/" rel="tag">ClassTag</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classical-Statistical-Inference/" rel="tag">Classical Statistical Inference</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Clustering/" rel="tag">Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Co-training/" rel="tag">Co-training</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CompletionService/" rel="tag">CompletionService</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ConcurrentHashMap/" rel="tag">ConcurrentHashMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ConcurrentLinkedQueue/" rel="tag">ConcurrentLinkedQueue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ConcurrentModificationException/" rel="tag">ConcurrentModificationException</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Condition-Queue/" rel="tag">Condition Queue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Constrained-Seed-k-means/" rel="tag">Constrained Seed k-means</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Constrained-k-means/" rel="tag">Constrained k-means</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Context-Switching/" rel="tag">Context Switching</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CopyOnWriteArrayList/" rel="tag">CopyOnWriteArrayList</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CountDownLatch/" rel="tag">CountDownLatch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Counting/" rel="tag">Counting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DARTS/" rel="tag">DARTS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DARTS-PT/" rel="tag">DARTS+PT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DBSCAN/" rel="tag">DBSCAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DCL/" rel="tag">DCL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DDPG/" rel="tag">DDPG</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/" rel="tag">DL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DP/" rel="tag">DP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DPG/" rel="tag">DPG</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DPoS/" rel="tag">DPoS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DQN/" rel="tag">DQN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Daemon-Thread/" rel="tag">Daemon Thread</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deadlock/" rel="tag">Deadlock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Tree/" rel="tag">Decision Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Density-based-Clustering/" rel="tag">Density-based Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deque/" rel="tag">Deque</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Derivative/" rel="tag">Derivative</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dictionary-Learning/" rel="tag">Dictionary Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dijkstra/" rel="tag">Dijkstra</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dimension-Reduction/" rel="tag">Dimension Reduction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Directional-Derivative/" rel="tag">Directional Derivative</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Discrete-Uniform-Distribution/" rel="tag">Discrete Uniform Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Diversity-Enhance/" rel="tag">Diversity Enhance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Diversity-Measure/" rel="tag">Diversity Measure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dockerfile/" rel="tag">Dockerfile</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Double-DQN/" rel="tag">Double DQN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Double-Q-learning/" rel="tag">Double Q-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dueling-DQN/" rel="tag">Dueling DQN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dutch-Trace/" rel="tag">Dutch Trace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EI/" rel="tag">EI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ENAS/" rel="tag">ENAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ERM/" rel="tag">ERM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Edmonds-Karp/" rel="tag">Edmonds-Karp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Eligibility-Trace/" rel="tag">Eligibility Trace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ensemble-Learning/" rel="tag">Ensemble Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ensemble-Selection/" rel="tag">Ensemble Selection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EnumMap/" rel="tag">EnumMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EnumSet/" rel="tag">EnumSet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Erlang-Distribution/" rel="tag">Erlang Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Error-Rate/" rel="tag">Error Rate</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Escape-Analysis/" rel="tag">Escape Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Evolutionary-Algorithm/" rel="tag">Evolutionary Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Exclusive-Locks/" rel="tag">Exclusive Locks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Executor/" rel="tag">Executor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ExecutorService/" rel="tag">ExecutorService</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Expectation/" rel="tag">Expectation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Exploration-Exploitation-dilemma/" rel="tag">Exploration-Exploitation dilemma</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Exponential-Distribution/" rel="tag">Exponential Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/F1-Measure/" rel="tag">F1 Measure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FLP/" rel="tag">FLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Factory-Method-Pattern/" rel="tag">Factory Method Pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fair-DARTS/" rel="tag">Fair DARTS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fair-Lock/" rel="tag">Fair Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FairNAS/" rel="tag">FairNAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Feature-Selection/" rel="tag">Feature Selection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FetchFailedException/" rel="tag">FetchFailedException</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Floyd-Warshall/" rel="tag">Floyd-Warshall</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ford-Fulkerson/" rel="tag">Ford-Fulkerson</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Future/" rel="tag">Future</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FutureTask/" rel="tag">FutureTask</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GBDT/" rel="tag">GBDT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GC/" rel="tag">GC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GDBT-NAS/" rel="tag">GDBT-NAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GFS/" rel="tag">GFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GP/" rel="tag">GP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Geometric-Distribution/" rel="tag">Geometric Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gibbs-Sampling/" rel="tag">Gibbs Sampling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gini-Index/" rel="tag">Gini Index</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gradient/" rel="tag">Gradient</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gradient-Descent/" rel="tag">Gradient Descent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GreedyNAS/" rel="tag">GreedyNAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HA/" rel="tag">HA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HDFS/" rel="tag">HDFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HMM/" rel="tag">HMM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HPO/" rel="tag">HPO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Happens-Before/" rel="tag">Happens-Before</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hash-Based-Shuffle/" rel="tag">Hash-Based Shuffle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hedged-Read/" rel="tag">Hedged Read</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hermitan-Matrix/" rel="tag">Hermitan Matrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hierarchical-Clustering/" rel="tag">Hierarchical Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hinge-Regression/" rel="tag">Hinge Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hoeffding-s-Inequality/" rel="tag">Hoeffding&#39;s Inequality</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hot-Fields/" rel="tag">Hot Fields</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HuffmanCode/" rel="tag">HuffmanCode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HyperNet/" rel="tag">HyperNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hyperband/" rel="tag">Hyperband</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hyperopt/" rel="tag">Hyperopt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hypothesis-Test/" rel="tag">Hypothesis Test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ID3/" rel="tag">ID3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Imitation-Learning/" rel="tag">Imitation Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Importance-Sampling/" rel="tag">Importance Sampling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Independence/" rel="tag">Independence</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-Entropy/" rel="tag">Information Entropy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-Gain/" rel="tag">Information Gain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-Gain-Ratio/" rel="tag">Information Gain Ratio</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Interruptible-Lock/" rel="tag">Interruptible Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Isometry/" rel="tag">Isometry</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JVM/" rel="tag">JVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jensen-s-Inequality/" rel="tag">Jensen&#39;s  Inequality</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Johnson/" rel="tag">Johnson</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K-armed-bandit/" rel="tag">K-armed bandit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K-means/" rel="tag">K-means</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KLDA/" rel="tag">KLDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KMP/" rel="tag">KMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KPCA/" rel="tag">KPCA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KTT/" rel="tag">KTT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kernel-Function/" rel="tag">Kernel Function</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kruskal/" rel="tag">Kruskal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LASSO/" rel="tag">LASSO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LATE/" rel="tag">LATE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LCS/" rel="tag">LCS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LDA/" rel="tag">LDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLMS/" rel="tag">LLMS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LMS/" rel="tag">LMS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSM/" rel="tag">LSM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTD/" rel="tag">LSTD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTM/" rel="tag">LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LVQ/" rel="tag">LVQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LVW/" rel="tag">LVW</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lagrange-Multiplier/" rel="tag">Lagrange Multiplier</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Laplacian-Correction/" rel="tag">Laplacian Correction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lasso-Regression/" rel="tag">Lasso Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Latch/" rel="tag">Latch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Law-of-Large-Numbers/" rel="tag">Law of Large Numbers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Least-Squares/" rel="tag">Least Squares</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LightGBM/" rel="tag">LightGBM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Likelihood-Ratio/" rel="tag">Likelihood Ratio</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear-Algebra/" rel="tag">Linear Algebra</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear-Regression/" rel="tag">Linear Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LinkedList/" rel="tag">LinkedList</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Livelock/" rel="tag">Livelock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lock-Coarsening/" rel="tag">Lock Coarsening</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lock-Contention/" rel="tag">Lock Contention</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lock-Granularity/" rel="tag">Lock Granularity</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lock-Scope/" rel="tag">Lock Scope</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lock-Striping/" rel="tag">Lock Striping</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Logistic-Regression/" rel="tag">Logistic Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MAP/" rel="tag">MAP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MDP/" rel="tag">MDP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MDS/" rel="tag">MDS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/" rel="tag">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MLE/" rel="tag">MLE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MRv1/" rel="tag">MRv1</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MSE/" rel="tag">MSE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MST/" rel="tag">MST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Macro-Average/" rel="tag">Macro Average</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/" rel="tag">MapReduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mark-Word/" rel="tag">Mark Word</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markov-Chain/" rel="tag">Markov Chain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markov-chain/" rel="tag">Markov chain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markov-s-Inequality/" rel="tag">Markov&#39;s Inequality</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Matrix-Completion/" rel="tag">Matrix Completion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mean/" rel="tag">Mean</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MemTable/" rel="tag">MemTable</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Memory-Synchronization/" rel="tag">Memory Synchronization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Memory-Bank/" rel="tag">Memory-Bank</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Micro-Average/" rel="tag">Micro Average</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mixture-of-Gaussian/" rel="tag">Mixture-of-Gaussian</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Monte-Carlo-Learning/" rel="tag">Monte Carlo Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Monte-Carlo-Methods/" rel="tag">Monte Carlo Methods</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Morris-Traversal/" rel="tag">Morris Traversal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Multivariate-Decision-Tree/" rel="tag">Multivariate Decision Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/" rel="tag">Mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NAO/" rel="tag">NAO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NAS/" rel="tag">NAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NASNet/" rel="tag">NASNet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NASP/" rel="tag">NASP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NSGA-II/" rel="tag">NSGA-II</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Naive-Bayes-Classifiers/" rel="tag">Naive Bayes Classifiers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NoisyDARTS/" rel="tag">NoisyDARTS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Normal/" rel="tag">Normal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Normal-Distribution/" rel="tag">Normal Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ODE/" rel="tag">ODE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Observer-Pattern/" rel="tag">Observer Pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/One-Shot/" rel="tag">One-Shot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Open-Call/" rel="tag">Open Call</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Optimistic-Lock/" rel="tag">Optimistic Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/P-DARTS/" rel="tag">P-DARTS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PAC/" rel="tag">PAC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PBFT/" rel="tag">PBFT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PC-DARTS/" rel="tag">PC-DARTS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PCA/" rel="tag">PCA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PDF/" rel="tag">PDF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PGD/" rel="tag">PGD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PI/" rel="tag">PI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PMF/" rel="tag">PMF</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PR/" rel="tag">PR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Partial-Derivative/" rel="tag">Partial Derivative</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pascal-Distribution/" rel="tag">Pascal Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Paxos/" rel="tag">Paxos</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pessimistic-Lock/" rel="tag">Pessimistic Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Piggyback/" rel="tag">Piggyback</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PoS/" rel="tag">PoS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PoW/" rel="tag">PoW</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Poison-Pill/" rel="tag">Poison Pill</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Poisson-Distribution/" rel="tag">Poisson Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Policy-Gradient/" rel="tag">Policy Gradient</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Polled-Lock/" rel="tag">Polled Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Possion-Process/" rel="tag">Possion Process</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Precision/" rel="tag">Precision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Prim/" rel="tag">Prim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Probability/" rel="tag">Probability</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Protoytpe-based-Clustering/" rel="tag">Protoytpe-based Clustering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ProxylessNAS/" rel="tag">ProxylessNAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Publish-Subscribe-Pattern/" rel="tag">Publish-Subscribe Pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Q-learning/" rel="tag">Q-learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/REINFORCE/" rel="tag">REINFORCE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RIP/" rel="tag">RIP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RL/" rel="tag">RL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RMQ/" rel="tag">RMQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROAR/" rel="tag">ROAR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROC/" rel="tag">ROC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Raft/" rel="tag">Raft</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Random-Forest/" rel="tag">Random Forest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Rayleigh-quotient/" rel="tag">Rayleigh quotient</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Read-Write-Lock/" rel="tag">Read-Write Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recall/" rel="tag">Recall</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReenTrantLock/" rel="tag">ReenTrantLock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reentrant-Lock/" rel="tag">Reentrant Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ReentrantReadWriteLock/" rel="tag">ReentrantReadWriteLock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-Learning/" rel="tag">Reinforcement Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Relief/" rel="tag">Relief</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Relief-F/" rel="tag">Relief-F</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reordering/" rel="tag">Reordering</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Replacing-Trace/" rel="tag">Replacing Trace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Robbins-Monro/" rel="tag">Robbins-Monro</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/S3VM/" rel="tag">S3VM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SAMR/" rel="tag">SAMR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SARSA/" rel="tag">SARSA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SGD/" rel="tag">SGD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SHAP/" rel="tag">SHAP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMAC/" rel="tag">SMAC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMASH/" rel="tag">SMASH</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMBO/" rel="tag">SMBO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMO/" rel="tag">SMO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SNAS/" rel="tag">SNAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SPFA/" rel="tag">SPFA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SPOS/" rel="tag">SPOS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SRM/" rel="tag">SRM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SSTable/" rel="tag">SSTable</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVD/" rel="tag">SVD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVR/" rel="tag">SVR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sarsa/" rel="tag">Sarsa</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Saturation-Policies/" rel="tag">Saturation Policies</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Self-Adjont/" rel="tag">Self-Adjont</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Semaphore/" rel="tag">Semaphore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Semi-Gradient-Descent/" rel="tag">Semi-Gradient Descent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Semi-naive-Bayes-Classifiers/" rel="tag">Semi-naive Bayes Classifiers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Semi-supervised-Learning/" rel="tag">Semi-supervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SemiNAS/" rel="tag">SemiNAS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sequential-Consistency/" rel="tag">Sequential Consistency</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shuffle/" rel="tag">Shuffle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shutdown-Hock/" rel="tag">Shutdown Hock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Significance-Test/" rel="tag">Significance Test</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Simple-Factory-Pattern/" rel="tag">Simple Factory Pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Single-Path/" rel="tag">Single Path</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SinglePath/" rel="tag">SinglePath</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SnowFlake/" rel="tag">SnowFlake</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Softmax/" rel="tag">Softmax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sort-Based-Shuffle/" rel="tag">Sort-Based Shuffle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark-SQL/" rel="tag">Spark SQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sparse-Coding/" rel="tag">Sparse Coding</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sparse-Representation/" rel="tag">Sparse Representation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sparse-Table/" rel="tag">Sparse Table</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spectral-Theorem/" rel="tag">Spectral Theorem</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Speculative-Task/" rel="tag">Speculative Task</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Stack/" rel="tag">Stack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Starvation/" rel="tag">Starvation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Statistics/" rel="tag">Statistics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Stochastic-Process/" rel="tag">Stochastic Process</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Strategy-Pattern/" rel="tag">Strategy Pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Strong-Law-of-Large-Numbers/" rel="tag">Strong Law of Large Numbers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Student-s-t-distribution/" rel="tag">Student&#39;s t-distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SuccessiveHalving/" rel="tag">SuccessiveHalving</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Supervised-Learning/" rel="tag">Supervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Synchronizer/" rel="tag">Synchronizer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TD3/" rel="tag">TD3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TPE/" rel="tag">TPE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TSVM/" rel="tag">TSVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Temporal-Difference-Learning/" rel="tag">Temporal Difference Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Temporal-Difference-Learning/" rel="tag">Temporal-Difference Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ThreadLocal/" rel="tag">ThreadLocal</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ThreadPoolExecutor/" rel="tag">ThreadPoolExecutor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Timed-Lock/" rel="tag">Timed Lock</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Total-Derivative/" rel="tag">Total Derivative</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Total-Probability-Theorem/" rel="tag">Total Probability Theorem</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tungsten-Sort-Shuffle/" rel="tag">Tungsten-Sort Shuffle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UCB/" rel="tag">UCB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Uniform-Distribution/" rel="tag">Uniform Distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unitary-Matrix/" rel="tag">Unitary Matrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Univariate-Decision-Tree/" rel="tag">Univariate Decision Tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unsupervised-Learning/" rel="tag">Unsupervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Variance/" rel="tag">Variance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VisualVM/" rel="tag">VisualVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Viterbi/" rel="tag">Viterbi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Weak-Law-of-Large-Numbers/" rel="tag">Weak Law of Large Numbers</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Weight-Sharing/" rel="tag">Weight Sharing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Weights-Sharing/" rel="tag">Weights Sharing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Work-Stealing/" rel="tag">Work Stealing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XGBoost/" rel="tag">XGBoost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/YARN/" rel="tag">YARN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/abstract-class/" rel="tag">abstract class</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/adjacency-matrix/" rel="tag">adjacency matrix</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithms/" rel="tag">algorithms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/augmenting-path/" rel="tag">augmenting path</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/big-data/" rel="tag">big data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/big-integer/" rel="tag">big integer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bilevel-optimization/" rel="tag">bilevel optimization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bit-manipulation/" rel="tag">bit manipulation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blockchain/" rel="tag">blockchain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/builder/" rel="tag">builder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/char/" rel="tag">char*</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cloud-cmputing/" rel="tag">cloud cmputing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cloud-computing/" rel="tag">cloud computing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/column-key/" rel="tag">column key</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/constructor/" rel="tag">constructor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/context-bounds/" rel="tag">context bounds</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/contravariance/" rel="tag">contravariance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/covariance/" rel="tag">covariance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-structure/" rel="tag">data structure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/decoder/" rel="tag">decoder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deserializing/" rel="tag">deserializing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/direct-memory/" rel="tag">direct memory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/divide-and-conquer/" rel="tag">divide and conquer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/encoder/" rel="tag">encoder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/epectation-Maximization-Algorithm/" rel="tag">epectation-Maximization Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/epsilon-Greedy/" rel="tag">epsilon-Greedy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/equals/" rel="tag">equals</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/every-visit-Monte-Carlo-update/" rel="tag">every visit Monte Carlo update</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/existential-type/" rel="tag">existential type</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/experience-repaly/" rel="tag">experience repaly</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/exploring-start/" rel="tag">exploring start</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fast-matrix-exponentiation/" rel="tag">fast matrix exponentiation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/first-visit-Monte-Carlo-update/" rel="tag">first visit Monte Carlo update</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/function-approximation/" rel="tag">function approximation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/functional-programming/" rel="tag">functional programming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/generalized-suffix-tree/" rel="tag">generalized suffix tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/" rel="tag">go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/graph/" rel="tag">graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/graph-database/" rel="tag">graph database</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/greedy/" rel="tag">greedy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/handle/" rel="tag">handle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heuristic-approaches/" rel="tag">heuristic approaches</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/higher-kinded-types/" rel="tag">higher kinded types</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/history-server/" rel="tag">history server</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/history-sever/" rel="tag">history sever</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/id/" rel="tag">id</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/images/" rel="tag">images</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/immutable/" rel="tag">immutable</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/implicit/" rel="tag">implicit</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/inorder/" rel="tag">inorder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/interrupt/" rel="tag">interrupt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/invariance/" rel="tag">invariance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/invokeAll/" rel="tag">invokeAll</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java-bean/" rel="tag">java bean</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jinfo/" rel="tag">jinfo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jmao/" rel="tag">jmao</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jps/" rel="tag">jps</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jstack/" rel="tag">jstack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jstat/" rel="tag">jstat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leveldb/" rel="tag">leveldb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/log4j/" rel="tag">log4j</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/manifest/" rel="tag">manifest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maximum-bipartite-matching/" rel="tag">maximum bipartite matching</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maxium-flow/" rel="tag">maxium flow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mutiply-inheritance/" rel="tag">mutiply inheritance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/newTaskFor/" rel="tag">newTaskFor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/object-pool/" rel="tag">object pool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/object-serialization/" rel="tag">object serialization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/off-policy/" rel="tag">off-policy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/on-policy/" rel="tag">on-policy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/override/" rel="tag">override</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/path-dependent-type/" rel="tag">path-dependent type</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/policy-evaluation/" rel="tag">policy evaluation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/policy-gradient/" rel="tag">policy gradient</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/policy-improvement/" rel="tag">policy improvement</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/policy-iteration/" rel="tag">policy iteration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/postorder/" rel="tag">postorder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/preorder/" rel="tag">preorder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reachability-analysis/" rel="tag">reachability analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/readObject/" rel="tag">readObject</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/readResolve/" rel="tag">readResolve</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reference-chain/" rel="tag">reference chain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reference-counting/" rel="tag">reference counting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reflect/" rel="tag">reflect</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rm/" rel="tag">rm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/row-key/" rel="tag">row key</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/" rel="tag">scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/segment-tree/" rel="tag">segment tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/semaphore/" rel="tag">semaphore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sequence-to-sequence/" rel="tag">sequence-to-sequence</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/serialization-proxy-pattern/" rel="tag">serialization proxy pattern</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/serializing/" rel="tag">serializing</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/singleton/" rel="tag">singleton</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/skiplist/" rel="tag">skiplist</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/soft-policy/" rel="tag">soft policy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sort/" rel="tag">sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/specialized-method/" rel="tag">specialized method</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/static-factory-method/" rel="tag">static factory method</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/string/" rel="tag">string</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/structural-type/" rel="tag">structural type</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sudo/" rel="tag">sudo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tail-recursion/" rel="tag">tail recursion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/target-network/" rel="tag">target network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tee/" rel="tag">tee</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/telescoping-Constructor/" rel="tag">telescoping Constructor</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/trait/" rel="tag">trait</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tree/" rel="tag">tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/type/" rel="tag">type</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/type-projection/" rel="tag">type projection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unconfigurableExecutorService/" rel="tag">unconfigurableExecutorService</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/value-iteration/" rel="tag">value iteration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/variable-length-code/" rel="tag">variable-length code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/variance/" rel="tag">variance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/view-bounds/" rel="tag">view bounds</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/" rel="tag">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/writeObject/" rel="tag">writeObject</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/writeReplace/" rel="tag">writeReplace</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/yum/" rel="tag">yum</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%8D%E5%BF%85%E8%A6%81%E5%AF%B9%E8%B1%A1/" rel="tag">不必要对象</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%AA%E5%AD%97%E8%8A%82%E6%B5%81%E6%94%BB%E5%87%BB/" rel="tag">伪字节流攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%85%E9%83%A8%E5%9F%9F%E7%9B%97%E7%94%A8%E6%94%BB%E5%87%BB/" rel="tag">内部域盗用攻击</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%AF%E4%BC%B8%E7%BC%A9/" rel="tag">可伸缩</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8%E5%8F%91%E5%B8%83/" rel="tag">安全发布</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B9%B6%E5%8F%91/" rel="tag">并发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%9A%E4%B8%BE/" rel="tag">枚举</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%88%E5%B0%81%E9%97%AD/" rel="tag">栈封闭</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AD%96%E7%95%A5%E6%9E%9A%E4%B8%BE/" rel="tag">策略枚举</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%B4%A2%E5%BC%95/" rel="tag">索引</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/" rel="tag">虚拟化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%87%E6%9C%9F%E5%AF%B9%E8%B1%A1/" rel="tag">过期对象</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%B8%E5%87%BA/" rel="tag">逸出</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%87%8D%E5%85%A5/" rel="tag">重入</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%87%8D%E6%8E%92%E5%BA%8F/" rel="tag">重排序</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%90%E5%BC%8F%E4%BD%9C%E7%94%A8%E5%9F%9F/" rel="tag">隐式作用域</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%90%E5%BC%8F%E5%8F%82%E6%95%B0/" rel="tag">隐式参数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%90%E5%BC%8F%E8%A7%86%E5%9B%BE/" rel="tag">隐式视图</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2/" rel="tag">隐式转换</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://www.google.com/">Google</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://stackoverflow.com/">StackOverflow</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://leetcode.com/problemset/algorithms/">LeetCode</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://www.youtube.com/">YouTube</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">什么都想学，什么都学不会。</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页"></a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页"></a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0">读书笔记</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:hazzacheng@gmail.com" title="Email"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa Github" target="_blank" href="https://github.com/HazzaCheng" title="Github"></a>
                            
                                <a class="fa 知乎" target="_blank" href="https://www.zhihu.com/people/hazzacheng" title="知乎"></a>
                            
                                <a class="fa 豆瓣" target="_blank" href="https://www.douban.com/people/HazzaCheng/" title="豆瓣"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-强化学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
      <time datetime="2019-06-08T13:47:50.000Z" itemprop="datePublished">2019-06-08</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习基础（十二）- 强化学习笔记
    </h1>
  

        <div style="margin-top:10px;">
    <span class="post-time">
      <span class="post-meta-item-icon">
        <i class="fa fa-keyboard-o"></i>
        <span class="post-meta-item-text">  字数统计: </span>
        <span class="post-count">9.2k 字</span>
      </span>
    </span>

    <span class="post-time">
      &nbsp; | &nbsp;
      <span class="post-meta-item-icon">
        <i class="fa fa-hourglass-half"></i>
        <span class="post-meta-item-text">  阅读时长: </span>
        <span class="post-count">37 分</span>
      </span>
    </span>

    
        <span id="busuanzi_container_page_pv">
          &nbsp; | &nbsp;  本文总阅读量: <span id="busuanzi_value_page_pv"></span> 次
        </span>
    
</div>

        <br>
      </header>
      
      <div class="article-info article-info-post">
        
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/AI/">AI</a><a class="article-category-link" href="/categories/AI/Machine-Learning/">Machine Learning</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DP/" rel="tag">DP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Exploration-Exploitation-dilemma/" rel="tag">Exploration-Exploitation dilemma</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Imitation-Learning/" rel="tag">Imitation Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/K-armed-bandit/" rel="tag">K-armed bandit</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MDP/" rel="tag">MDP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/" rel="tag">ML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Monte-Carlo-Learning/" rel="tag">Monte Carlo Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Q-learning/" rel="tag">Q-learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Reinforcement-Learning/" rel="tag">Reinforcement Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Sarsa/" rel="tag">Sarsa</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Softmax/" rel="tag">Softmax</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Temporal-Difference-Learning/" rel="tag">Temporal Difference Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/epsilon-Greedy/" rel="tag">epsilon-Greedy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/policy-iteration/" rel="tag">policy iteration</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/value-iteration/" rel="tag">value iteration</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><strong><em>版权声明：本文原创，转载请留意文尾，如有侵权请留言，谢谢</em></strong></p>
<h1 id="引言">引言</h1>
<p>　　主要记录关于强化学习的一些笔记，强化学习主要分为基于动态规划的有模型学习和基于蒙特卡洛方法的免模型学习。</p>
<span id="more"></span>
<h1 id="强化学习reinforcement-learning">强化学习（Reinforcement
Learning）</h1>
<p>　　强化学习主要采用了任务与奖赏的思想，强化学习任务也通常用马尔可夫决策过程（Markov
Decision Process, MDP）来描述，可以用一个四元组<span class="math inline">\(E=&lt;X,A,P,R&gt;\)</span>来表示，其中<span class="math inline">\(E\)</span>表示机器所处的环境，<span class="math inline">\(x \in X\)</span>表示状态空间，<span class="math inline">\(a \in A\)</span>表示动作空间，<span class="math inline">\(P : X \times A \times X \mapsto
\mathbb{R}\)</span>指定了状态转移概率，<span class="math inline">\(R : X
\times A \times X \mapsto \mathbb{R}\)</span>指定了奖赏。<br>
　　下图是西瓜书中的给的一个非常形象的例子。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png"></p>
<p>　　机器要做的是在环境中不断尝试而学得一个策略（policy）<span class="math inline">\(\pi\)</span>，根据这个策略，在状态<span class="math inline">\(x\)</span>下执行的动作<span class="math inline">\(a=\pi(x)\)</span>。策略有两种表达方式：</p>
<ul>
<li>一种是表示为函数<span class="math inline">\(\pi : X \mapsto
A\)</span>，确定性策略常用这方式。</li>
<li>另一种是用概率表示<span class="math inline">\(\pi : X \times A
\mapsto \mathbb{R}\)</span>，随机性策略常用这种方式，<span class="math inline">\(\pi(x, a)\)</span>表示在状态<span class="math inline">\(x\)</span>下选择动作<span class="math inline">\(a\)</span>的概率，其中<span class="math inline">\(\sum_{a} \pi(x, a)=1\)</span>。</li>
</ul>
<p>　　策略的优劣取决于长期执行这一策略后得到的累积奖赏，在强化学习的任务中，学习的目的也就是找到能使长期累积奖赏最大化的策略，长期累积奖赏有多种计算方式，常用的有两种：</p>
<ul>
<li><span class="math inline">\(T\)</span>步累积奖赏：<span class="math inline">\(\mathbb{E}\left[\frac{1}{T} \sum_{t=1}^{T}
r_{t}\right]\)</span></li>
<li><span class="math inline">\(\gamma\)</span>折扣累积奖赏：<span class="math inline">\(\mathbb{E}\left[\sum_{t=0}^{+\infty} \gamma^{t}
r_{t+1}\right]\)</span></li>
</ul>
<h1 id="k-摇臂赌博机"><span class="math inline">\(K\)</span>-摇臂赌博机</h1>
<h2 id="探索-利用窘境exploration-exploitation-dilemma">探索-利用窘境（Exploration-Exploitation
dilemma）</h2>
<p>　　与一般监督学习不同，强化学习任务的最终奖赏是在多步动作之后才能观察到，这里我们不妨先考虑比较简单的情形：最大化单步奖赏，即仅考虑一步操作。需注意的是，即便在这样的简化情形下，强化学习仍与监督学习有显著不同，因为机器需通过尝试来发现各个动作产生的结果，而没有训练数据告诉机器应当做哪个动作。<br>
　　欲最大化单步奖赏需考虑两个方面：一是需知道每个动作带来的奖赏，二是要执行奖赏最大的动作。若每个动作对应的奖赏是一个确定值，那么尝试一遍所有的动作便能找出奖赏最大的动作。然而，更一般的情形是，一个动作的奖赏值是来自于一个概率分布，仅通过一次尝试并不能确切地获得平均奖赏值。<br>
　　单步强化学习任务对应了一个理论模型，即<span class="math inline">\(K\)</span>-摇臂赌博机”（K-armed
bandit）。赌博机有<span class="math inline">\(K\)</span>个摇臂，赌徒在投入一个硬币后可选择按下其中一个摇臂，每个摇臂以一定的概率吐出硬币，但这个概率赌徒并不知道。赌徒的目标是通过一定的策略最大化自己的奖赏，即获得最多的硬币，通常有两种策略：</p>
<ul>
<li>若仅为获知每个摇臂的期望奖赏，则可采用“仅探索”（exploration-only）法：将所有的尝试机会平均分配给每个摇臂（即轮流按下每个摇臂），最后以每个摇臂各自的平均吐币概率作为其奖赏期望的近似估计。</li>
<li>若仅为执行奖赏最大的动作，则可采用“仅利用”（exploitation-only）法：按下目前最优的（即到目前为止平均奖赏最大的）摇臂，若有多个摇臂同为最优，则从中随机选取一个。</li>
</ul>
<p>　　“仅探索”法能很好地估计每个摇臂的奖赏，却会失去很多选择最优摇臂的机会。“仅利用”法则相反，它没有很好地估计摇臂期望奖赏，很可能经常选不到最优摇臂。这两种方法都难以使最终的累积奖赏最大化。“探索”（即估计摇臂的优劣）和“利用”（即选择当前最优摇臂）这两者是矛盾的，因为尝试次数（即总投币数）有限，加强了一方则会自然削弱另一方，这就是强化学习所面临的“探索-利用窘境。</p>
<h2 id="epsilon-贪心epsilon-greedy"><span class="math inline">\(\epsilon\)</span>-贪心（epsilon-Greedy）</h2>
<p>　　显然，欲累积奖赏最大，则必须在探索与利用之间达成较好的折中贪心。<span class="math inline">\(\epsilon\)</span>-贪心法基于一个概率<span class="math inline">\(\epsilon\)</span>来对探索和利用进行折中：每次尝试时，以<span class="math inline">\(\epsilon\)</span>的概率进行探索，即以均匀概率随机选取一个摇臂，以<span class="math inline">\(1-
\epsilon\)</span>的概率进行利用，即选择当前平均奖赏最高的摇臂（若有多个，则随机选取一个）。<br>
　　<span class="math inline">\(Q(k)\)</span>记录摇臂<span class="math inline">\(k\)</span>的平均奖赏，若摇臂<span class="math inline">\(k\)</span>被尝试了<span class="math inline">\(n\)</span>次，得到的奖赏为<span class="math inline">\(v_1,v_2,\cdots,v_n\)</span>，则平均奖赏为： <span class="math display">\[
Q(k)=\frac{1}{n} \sum_{i=1}^{n} v_{i} \qquad(1)
\]</span> 　　<span class="math inline">\(Q_{n}(k)\)</span>也可以如式(2)一样进行增量式更新，这样无论摇臂被尝试了多少次，也只需要记录两个值。<br>
<span class="math display">\[
\begin{aligned}
Q_{n}(k)&amp;=\frac{1}{n}\left((n-1) \times Q_{n-1}(k)+v_{n}\right) \\
&amp;=Q_{n-1}(k)+\frac{1}{n}\left(v_{n}-Q_{n-1}(k)\right) \qquad(2)
\end{aligned}
\]</span> 　　算法流程图如下图所示。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.png"></p>
<p>　　若摇臂奖赏的不确定性较大，例如概率分布较宽时，则需更多的探索，此时需要较大的<span class="math inline">\(\epsilon\)</span>值。若摇臂的不确定性较小，例如概率分布较集中时，则少量的尝试就能很好地近似真实奖赏，此时需要的<span class="math inline">\(\epsilon\)</span>较小。若尝试次数非常大，那么在一段时间后，摇臂的奖赏都能很好地近似出来，不再需要探索，这种情形下可让<span class="math inline">\(\epsilon\)</span>随着尝试次数的增加而逐渐减小，例如<span class="math inline">\(\epsilon = \frac{1}{\sqrt{t}}\)</span>。</p>
<h2 id="softmax">Softmax</h2>
<p>　　Softmax算法基于当前己知的摇臂平均奖赏来对探索和利用进行折中。若各摇臂的平均奖赏相当，则选取各摇臂的概率也相当。若某些摇臂的平均奖赏明显高于其他摇臂，则它们被选取的概率也明显更高。Softmax算法中摇臂概率的分配是基于Boltzmann分布：
<span class="math display">\[
P(k)=\frac{e^{\frac{Q(k)}{\tau}}}{\sum_{i=1}^{K} e^{\frac{Q(i)}{\tau}}}
\]</span> 　　其中，<span class="math inline">\(Q(i)\)</span>记录当前摇臂的平均奖赏，<span class="math inline">\(\tau&gt;0\)</span>称为温度，<span class="math inline">\(\tau\)</span>越小则平均奖赏高的摇臂被选取的概率越高，<span class="math inline">\(\tau\)</span>趋于0时Softmax将趋于“仅利用”，<span class="math inline">\(\tau\)</span>趋于无穷大时Softmax则将趋于“仅探索”。算法流程图如下：</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.png"></p>
<p>　　对于离散状态空间、离散动作空间上的多步强化学习任务，一种直接的办法是将每个状态上动作的选择看作一个<span class="math inline">\(K\)</span>-摇臂赌博机问题，用强化学习任务的累积奖赏来代替<span class="math inline">\(K\)</span>-摇臂赌博机算法中的奖赏函数，即可将赌博机算法用于每个状态：对每个状态分别记录各动作的尝试次数、当前平均累积奖赏等信息，基于赌博机算法选择要尝试的动作。然而这样的做法有很多局限，因为它没有考虑强化学习任务马尔可夫决策过程的结构，若能有效考虑马尔可夫决策过程的特性，则可有更聪明的办法。</p>
<h1 id="有模型的学习model-based-learning">有模型的学习（model-based
learning）</h1>
<p>　　模型已知指的是四元组<span class="math inline">\(E=&lt;X,A,P,R&gt;\)</span>均为已知，在已知模型的环境中学习称为有模型学习。此时<span class="math inline">\(P_{x \rightarrow x^{\prime}}^{a}\)</span>和<span class="math inline">\(R_{x \rightarrow
x^{\prime}}^{a}\)</span>均是己知的。为便于讨论，不妨假设状态空间<span class="math inline">\(X\)</span>和动作空间<span class="math inline">\(A\)</span>均为有限空间。</p>
<h2 id="策略评估">策略评估</h2>
<p>　　在模型己知时，对任意策略<span class="math inline">\(\pi\)</span>能估计出该策略带来的期望累积奖赏。记函数<span class="math inline">\(V^{\pi}(x)\)</span>表示从状态<span class="math inline">\(x\)</span>出发，使用策略<span class="math inline">\(\pi\)</span>所带来的累积奖赏。函数<span class="math inline">\(Q^{\pi}(x, a)\)</span>表示从状态<span class="math inline">\(x\)</span>出发，执行动作<span class="math inline">\(a\)</span>后再使用策略<span class="math inline">\(\pi\)</span>带来的累积奖赏。这里<span class="math inline">\(V(\cdot)\)</span>称为“状态值函数”( state value
function），<span class="math inline">\(Q(\cdot)\)</span>称为“状态-动作值函数”（state-action
value
function），分别表示指定“状态”上以及指定“状态-动作”上的累积奖赏。<br>
　　由累积奖赏的定义，有状态值函数： <span class="math display">\[
\left\{\begin{aligned} V_{T}^{\pi}(x)
&amp;=\mathbb{E}_{\pi}\left[\frac{1}{T} \sum_{t=1}^{T} r_{t} |
x_{0}=x\right], &amp; T步累积奖赏 \\ V_{\gamma}^{\pi}(x)
&amp;=\mathbb{E}_{\pi}\left[\sum_{t=0}^{+\infty} \gamma^{t} r_{t+1} |
x_{0}=x\right],&amp; \gamma折扣累积奖赏 \end{aligned}\right. \qquad(3)
\]</span> 　　令<span class="math inline">\(x_0\)</span>表示起始状态，<span class="math inline">\(a_0\)</span>表示起始状态上采取的第一个动作，对于<span class="math inline">\(T\)</span>步累积奖赏，用下标<span class="math inline">\(t\)</span>表示后续执行的步数，我们有状态-动作值函数：
<span class="math display">\[
\left\{\begin{array}{l}{Q_{T}^{\pi}(x,
a)=\mathbb{E}_{\pi}\left[\frac{1}{T} \sum_{t=1}^{T} r_{t} | x_{0}=x,
a_{0}=a\right]} \\ {Q_{\gamma}^{\pi}(x,
a)=\mathbb{E}_{\pi}\left[\sum_{t=0}^{+\infty} \gamma^{t} r_{t+1} |
x_{0}=x, a_{0}=a\right]}\end{array}\right.　\qquad(4)
\]</span>
　　由于MDP具有马尔可夫性质，即系统下一时刻的状态仅由当前时刻的状态决定，不依赖于以往任何状态，于是值函数有很简单的递归形式，对于<span class="math inline">\(T\)</span>步累积奖赏有： <span class="math display">\[
\begin{aligned} V_{T}^{\pi}(x) &amp;=\mathbb{E}_{\pi}\left[\frac{1}{T}
\sum_{t=1}^{T} r_{t} | x_{0}=x\right] \\
&amp;=\mathbb{E}_{\pi}\left[\frac{1}{T} r_{1}+\frac{T-1}{T}
\frac{1}{T-1} \sum_{t=2}^{T} r_{t} | x_{0}=x\right] \\ &amp;=\sum_{a \in
A} \pi(x, a) \sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow
x^{\prime}}^{a}+\frac{T-1}{T} \mathbb{E}_{\pi}\left[\frac{1}{T-1}
\sum_{t=1}^{T-1} r_{t} | x_{0}=x^{\prime}\right]\right) \\ &amp;=\sum_{a
\in A} \pi(x, a) \sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow
x^{\prime}}^{a}+\frac{T-1}{T}
V_{T-1}^{\pi}\left(x^{\prime}\right)\right) \end{aligned} \qquad(5)
\]</span> 　　类似对于<span class="math inline">\(\gamma\)</span>折扣累积奖赏有： <span class="math display">\[
V_{\gamma}^{\pi}(x)=\sum_{a \in A} \pi(x, a) \sum_{x^{\prime} \in X}
P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow
x^{\prime}}^{a}+\gamma V_{\gamma}^{\pi}\left(x^{\prime}\right)\right)
\qquad(6)
\]</span> 　　需注意的是，正是由于<span class="math inline">\(P\)</span>和<span class="math inline">\(R\)</span>已知，才可以进行全概率展开。<br>
　　用上面的递归等式来计算值函数，实际上就是一种动态规划算法。对于<span class="math inline">\(V_{\gamma}^{\pi}(x)\)</span>可设想递归一直进行下去，直到最初的起点，也就是说，从值函数的初始值<span class="math inline">\(V_{0}^{\pi}\)</span>出发，通过一次迭代能计算出每个状态的单步奖赏<span class="math inline">\(V_{1}^{\pi}\)</span>，进而从单步奖赏出发，通过一次迭代计算出两步累积<span class="math inline">\(V_{2}^{\pi}\)</span>，以此递归循环，对于<span class="math inline">\(T\)</span>步累积奖赏，只需迭代<span class="math inline">\(T\)</span>轮就能精确地求出值函数。算法流程图如下图所示：</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.png"></p>
<p>　　对于<span class="math inline">\(V_{\gamma}^{\pi}\)</span>，由于<span class="math inline">\(\gamma^t\)</span>在<span class="math inline">\(t\)</span>很大时趋于0，因此也能使用类似的算法。由于算法可能会迭代很多次因此需设置一个停止准则，常见的是设置一个阈值<span class="math inline">\(\theta\)</span>，若在执行一次迭代后值函数的改变小于<span class="math inline">\(\theta\)</span>则算法停止，条件为<span class="math inline">\(\max _{x \in
X}\left|V(x)-V^{\prime}(x)\right|&lt;\theta\)</span>。<br>
　　有了状态值函数<span class="math inline">\(V\)</span>，就能直接计算出状态-动作值函数： <span class="math display">\[
\left\{\begin{aligned} Q_{T}^{\pi}(x, a) &amp;=\sum_{x^{\prime} \in X}
P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow
x^{\prime}}^{a}+\frac{T-1}{T}
V_{T-1}^{\pi}\left(x^{\prime}\right)\right) \\ Q_{\gamma}^{\pi}(x, a)
&amp;=\sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(R_{x
\rightarrow x^{\prime}}^{a}+\gamma
V_{\gamma}^{\pi}\left(x^{\prime}\right)\right) \end{aligned}\right.
\qquad(7)
\]</span></p>
<h2 id="策略改进">策略改进</h2>
<p>　　理想的策略应能最大化累积奖赏，即： <span class="math display">\[
\pi^{*}=\underset{\pi}{\arg \max } \sum_{x \in X} V^{\pi}(x) \qquad(8)
\]</span>
　　一个强化学习任务可能有多个最优策略，最优策略所对应的值函数<span class="math inline">\(V^*\)</span>称为最优值函数，即： <span class="math display">\[
\forall x \in X : V^{*}(x)=V^{\pi^{*}}(x) \qquad(9)
\]</span> 　　注意，当策略空间无约束时，式(9)的<span class="math inline">\(V^{*}\)</span>才是最优策略对应的值函数，例如对离散状态空间和离散动作空间，策略空间是所有状态上所有动作的组合，共有<span class="math inline">\(|A|^{|X|}\)</span>种不同的策略。若策略空间有约束，则违背约束的策略是不合法的，即便其值函数所取得的累积奖赏值最大，也不能作为最优值函数。<br>
　　由于最优值函数的累积奖赏值已达最大，可对前面的Bellman等式(5)和(6)做一个改动，即将对动作的求和改为取最优：
<span class="math display">\[
\left\{\begin{array}{l}{V_{T}^{*}(x)=\max _{a \in A} \sum_{x^{\prime}
\in X} P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x
\rightarrow x^{\prime}}^{a}+\frac{T-1}{T}
V_{T-1}^{*}\left(x^{\prime}\right)\right)} \\ {V_{\gamma}^{*}(x)=\max
_{a \in A} \sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma
V_{\gamma}^{*}\left(x^{\prime}\right)\right)}\end{array}\right.
\qquad(10)
\]</span> 　　也就是： <span class="math display">\[
V^{*}(x)=\max _{a \in A} Q^{\pi^{*}}(x, a) \qquad(11)
\]</span> 　　带入式(7)可得最优状态-动作值函数： <span class="math display">\[
\left\{\begin{array}{l}{Q_{T}^{*}(x, a)=\sum_{x^{\prime} \in X} P_{x
\rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow
x^{\prime}}^{a}+\frac{T-1}{T} \max _{a^{\prime} \in A}
Q_{T-1}^{*}\left(x^{\prime}, a^{\prime}\right)\right) ;} \\
{Q_{\gamma}^{*}(x, a)=\sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma \max
_{a^{\prime} \in A} Q_{\gamma}^{*}\left(x^{\prime},
a^{\prime}\right)\right)}\end{array}\right. \qquad(12)
\]</span>
　　上述关于最优值函数的等式，称为最优Bellman等式，其唯一解是最优值函数。最优Bellman等式揭示了非最优策略的改进方式：将策略选择的动作改变为当前最优的动作。显然，这样的改变能使策略更好。不妨令动作改变后对应的策略为<span class="math inline">\(\pi^{&#39;}\)</span>改变动作的条件为<span class="math inline">\(Q^{\pi}\left(x, \pi^{\prime}(x)\right) \geqslant
V^{\pi}(x)\)</span>，以<span class="math inline">\(\gamma\)</span>折扣累积奖赏为例，由式(7)可计算出递推不等式：
<span class="math display">\[
\begin{aligned} V^{\pi}(x) &amp; \leqslant Q^{\pi}\left(x,
\pi^{\prime}(x)\right) \\ &amp;=\sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{\pi^{\prime}(x)}\left(R_{x \rightarrow
x^{\prime}}^{\pi^{\prime}(x)}+\gamma
V^{\pi}\left(x^{\prime}\right)\right) \\ &amp; \leqslant
\sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{\pi^{\prime}(x)}\left(R_{x \rightarrow
x^{\prime}}^{\pi^{\prime}(x)}+\gamma Q^{\pi}\left(x^{\prime},
\pi^{\prime}\left(x^{\prime}\right)\right)\right) \\ &amp;=\cdots \\
&amp;= V^{\pi^{&#39;}}(x)\end{aligned} \qquad(13)
\]</span>
　　值函数对于策略的每一点改进都是单调递增的，因此对于当前策略<span class="math inline">\(\pi\)</span>，可放心地将其改进为： <span class="math display">\[
\pi^{\prime}(x)=\underset{a \in A}{\arg \max } Q^{\pi}(x, a) \qquad(14)
\]</span> 　　直到<span class="math inline">\(\pi\)</span>与<span class="math inline">\(\pi^{&#39;}\)</span>一致，不再发生变化，此时就满足了最优Bellman等式，即找到了最优策略。</p>
<h2 id="策略迭代policy-iteration与值迭代value-iteration">策略迭代（policy
iteration）与值迭代（value iteration）</h2>
<p>　　我们知道如何评估一个策略的值函数，并且知道在策略评估后如何改进至获得最优策略，将这两者结合起来即可得到求解最优解的方法，即从一个初始策略（通常是随机策略）出发，先进行策略评估，然后改进策略，评估改进的策略，再进一步改进策略，不断迭代进行策略评估和改进，直到策略收敛、不再改变为止，这样的做法称为策略迭代。下图是算法流程图（是基于<span class="math inline">\(T\)</span>步累积奖赏策略迭代算法）：</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.png"></p>
<p>　　类似的，可得到基于<span class="math inline">\(\gamma\)</span>折扣累积奖赏的策略迭代算法。策略迭代算法在每次改进策略后都需重新进行策略评估，这通常比较耗时。<br>
　　由式(3)可知，策略改进与值函数的改进是一致的，因此可将策略改进视为值函数的改善，即由式(10)可得：
<span class="math display">\[
\left\{\begin{array}{l}{V_{T}(x)=\max _{a \in A} \sum_{x^{\prime} \in X}
P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow
x^{\prime}}^{a}+\frac{T-1}{T} V_{T-1}\left(x^{\prime}\right)\right)} \\
{V_{\gamma}(x)=\max _{a \in A} \sum_{x^{\prime} \in X} P_{x \rightarrow
x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma
V_{\gamma}\left(x^{\prime}\right)\right)}\end{array}\right. \qquad(15)
\]</span> 　　这就是值迭代算法，算法流程图如下所示（是基于<span class="math inline">\(T\)</span>步累积奖赏的值迭代算法）：</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.png"></p>
<p>　　若采用<span class="math inline">\(\gamma\)</span>折扣累积奖赏，只需将上图算法中第3行替换为：
<span class="math display">\[
\forall x \in X : V^{\prime}(x)=\max _{a \in A} \sum_{x^{\prime} \in X}
P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow
x^{\prime}}^{a}+\gamma V\left(x^{\prime}\right)\right) \qquad(16)
\]</span>
　　从上面的算法可看出，在模型己知时强化学习任务实际上就是基于动态规划的寻优问题，与监督学习不同，这里并未涉及到泛化能力，而是为每一个状态找到最好的动作。</p>
<h1 id="免模型学习model-free-learning">免模型学习（model-free
learning）</h1>
<p>　　在现实的强化学习任务中，环境的转移概率、奖赏函数往往很难得知，甚至很难知道环境中一共有多少状态，若学习算法不依赖于环境建模，则称为免模型学习。</p>
<h2 id="蒙特卡罗强化学习monte-carlo-learning">蒙特卡罗强化学习（Monte
Carlo Learning）</h2>
<p>　　在免模型情形下，由于模型未知而导致无法做全概率展开，策略迭代算法无法进行策略无法评估，因此只能通过在环境中执行选择的动作，来观察转移的状态和得到的奖赏。受<span class="math inline">\(K\)</span>摇臂赌博机的启发，一种直接的策略评估替代方法是多次“采样”，然后求取平均累积奖赏来作为期望累积奖赏的近似，这就是蒙特卡罗强化学习，因为采样必须为有限次数，因此该方法更适合于使用<span class="math inline">\(T\)</span>步累积奖赏的强化学习任务。<br>
　　另一个麻烦的地方是，策略迭代算法估计的是状态值函数<span class="math inline">\(V\)</span>，而最终的策略是通过状态-动作值函数<span class="math inline">\(Q\)</span>来获得。当模型已知时，从<span class="math inline">\(V\)</span>到<span class="math inline">\(Q\)</span>有很简单的转换方法，而当模型未知时，这也会出现困难。于是，我们将估计对象从<span class="math inline">\(V\)</span>转变为<span class="math inline">\(Q\)</span>，即估计每一对状态-动作的值函数。<br>
　　此外，在模型未知的清形下，机器只能是从一个起始状态（或起始状态集合）开始探索环境，而策略迭代算法由于需对每个状态分别进行估计，因此，我们只能在探索的过程中逐渐发现各个状态并估计各状态动作对的值函数。<br>
　　综合起来在模型未知的情形下，我们从起始状态出发，使用某种策略进行采样，执行该策略<span class="math inline">\(T\)</span>步并获得轨迹<span class="math inline">\(&lt;x_{0}, a_{0}, r_{1}, x_{1}, a_{1}, r_{2},
\dots, x_{T-1}, a_{T-1}, r_{T},
x_{T}&gt;\)</span>。然后，对轨迹中出现的每一对状态-动作，记录其后的奖赏之和，作为该状态-动作对的一次累积奖赏采样值，多次采样得到多条轨迹后，将每个状态-动作对的累积奖赏采样值进行平均，即得到状态-动作值函数的估计。<br>
　　可以看出，欲较好地获得值函数的估计，就需要多条不同的采样轨迹。而我们的策略有可能是确定性的，即对于某个状态只会输出一个动作，若使用这样的策略进行采样，则只能得到多条相同的轨迹，这与<span class="math inline">\(K\)</span>摇臂赌博机的“仅利用”法面临相同的问题，因此可借鉴探索与利用折中的办法，例如使用<span class="math inline">\(\epsilon\)</span>-贪心法，以<span class="math inline">\(\epsilon\)</span>的概率从所有动作中均匀随机选取一个，以<span class="math inline">\(1-\epsilon\)</span>的概率选取当前最优动作，我们将确定性的策略<span class="math inline">\(\pi\)</span>称为“原始策略”，在原始策略上使用<span class="math inline">\(\epsilon\)</span>-贪心法的策略记为： <span class="math display">\[
\pi^{\epsilon}(x)=\left\{\begin{array}{l}{\pi(x),
\qquad\qquad\qquad\quad\quad\qquad以概率1-\epsilon} \\
{A中以均匀概率选取的动作, \qquad以概率\epsilon}\end{array}\right.
\qquad(17)
\]</span> 　　分析一下，对于最大化值函数的原始策略<span class="math inline">\(\pi=\arg \max _{a} Q(x, a)\)</span>，其<span class="math inline">\(\epsilon\)</span>-贪心策略<span class="math inline">\(\pi^\epsilon\)</span>中，当前最优动作被选中的概率是<span class="math inline">\(1-\epsilon+\frac{\epsilon}{|A|}\)</span>，而每个非最优动作被选中的概率是<span class="math inline">\(\frac{\epsilon}{|A|}\)</span>。于是，每个动作都有可能被选取，而多次采样将会产生不同的采样轨迹。<br>
　　与策略迭代算法类似，使用蒙特卡罗方法进行策略评估后，同样要对策略进行改进，与式(13)揭示的单调性类似，通过换入当前最优动作来改进策略，对于任意原始策略<span class="math inline">\(\pi\)</span>，其<span class="math inline">\(\epsilon\)</span>-贪心策略<span class="math inline">\(\pi^\epsilon\)</span>仅是将<span class="math inline">\(\epsilon\)</span>的概率均匀分配给所有动作，因此对于最大化值函数的原始策略<span class="math inline">\(\pi^{&#39;}\)</span>，同样有<span class="math inline">\(Q^{\pi}\left(x, \pi^{\prime}(x)\right) \geqslant
V^{\pi}(x)\)</span>，于是式(13)仍成立，即可以使用同样方法来进行策略改进。<br>
　　下图给出了同策略（on-policy）蒙特卡罗强化学习算法，即被评估与被改进的是同一个策略，算法中奖赏均值采用增量式计算，每采样出一条轨迹，就根据该轨迹涉及的所有“状态-动作”对来对值函数进行更新。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.png"></p>
<p>　　同策略蒙特卡罗强化学习算法最终产生的是<span class="math inline">\(\epsilon\)</span>-贪心策略，然而，引入<span class="math inline">\(\epsilon\)</span>-贪心是为了便于策略评估，在使用策略时并不需要<span class="math inline">\(\epsilon\)</span>-贪心。我们需要改进的是原始（非<span class="math inline">\(\epsilon\)</span>-贪心）策略。<br>
　　我们需要仅在策略评估时引入<span class="math inline">\(\epsilon\)</span>-贪心，而在策略改进时却改进原始策略。不妨用两个不同的策略<span class="math inline">\(\pi\)</span>和<span class="math inline">\(\pi^{&#39;}\)</span>来产生采样轨迹，两者的区别在于每个状态-动作对被采样的概率不同，函数<span class="math inline">\(f\)</span>在概率分布<span class="math inline">\(p\)</span>下的期望可表达为： <span class="math display">\[
\mathbb{E}[f]=\int_{x} p(x) f(x) \mathrm{d} x
\]</span> 　　通过从概率分布<span class="math inline">\(p\)</span>上的采样<span class="math inline">\(\{x_1,x_2,\cdots,x_m\}\)</span>来估计<span class="math inline">\(f\)</span>的期望，即： <span class="math display">\[
\hat{\mathbb{E}}[f]=\frac{1}{m} \sum_{i=1}^{m} f(x_i)
\]</span> 　　若引入另一个分布<span class="math inline">\(q\)</span>，则函数<span class="math inline">\(f\)</span>在概率分布<span class="math inline">\(p\)</span>下的期望也可等价地写为： <span class="math display">\[
\mathbb{E}[f]=\int_{x} q(x) \frac{p(x)}{q(x)} f(x) \mathrm{d} x
\]</span> 　　上式可看作<span class="math inline">\(\frac{p(x)}{q(x)}
f(x)\)</span>在分布<span class="math inline">\(q\)</span>下的期望，因此通过在<span class="math inline">\(q\)</span>上的采样<span class="math inline">\(\{x_1^{&#39;},x_2^{&#39;},\cdots,x_m^{&#39;}\}\)</span>可估计为：
<span class="math display">\[
\hat{\mathbb{E}}[f]=\frac{1}{m} \sum_{i=1}^{m}
\frac{p\left(x_{i}^{\prime}\right)}{q\left(x_{i}^{\prime}\right)}
f\left(x_{i}^{\prime}\right) \qquad(18)
\]</span> 　　使用策略<span class="math inline">\(\pi\)</span>的采样轨迹来评估策略<span class="math inline">\(\pi\)</span>，实际上就是对累积奖赏估计期望： <span class="math display">\[
Q(x, a)=\frac{1}{m} \sum_{i=1}^{m} R_{i}
\]</span> 　　其中<span class="math inline">\(R_i\)</span>表示第<span class="math inline">\(i\)</span>条轨迹上自状态<span class="math inline">\(x\)</span>至结束的累积奖赏，若改用策略<span class="math inline">\(\pi^{&#39;}\)</span>的采样轨迹来评估策略<span class="math inline">\(\pi\)</span>，则仅需对累积奖赏加权，即： <span class="math display">\[
Q(x, a)=\frac{1}{m} \sum_{i=1}^{m}
\frac{P_{i}^{\pi}}{P_{i}^{\pi^{\prime}}} R_{i}
\]</span> 　　其中<span class="math inline">\(P^{\pi}_i\)</span>和<span class="math inline">\(P^{\pi^{&#39;}}_i\)</span>分别表示两个策略产生第<span class="math inline">\(i\)</span>条轨迹的概率，对于给定的一条轨迹<span class="math inline">\(\left\langle x_{0}, a_{0}, r_{1}, \dots, x_{T-1},
a_{T-1}, r_{T}, x_{T}\right\rangle\)</span>，策略<span class="math inline">\(\pi\)</span>产生该轨迹的概率为： <span class="math display">\[
P^{\pi}=\prod_{i=0}^{T-1} \pi\left(x_{i}, a_{i}\right) P_{x_{i}
\rightarrow x_{i+1}}^{a_{i}}
\]</span> 　　虽然这里用到了环境的转移概率<span class="math inline">\(P_{x_{i} \rightarrow
x_{i+1}}^{a_{i}}\)</span>，但式(18)中实际只需两个策略概率的比值： <span class="math display">\[
\frac{P^{\pi}}{P^{\pi^{\prime}}}=\prod_{i=0}^{T-1} \frac{\pi\left(x_{i},
a_{i}\right)}{\pi^{\prime}\left(x_{i}, a_{i}\right)}
\]</span> 　　如果<span class="math inline">\(\pi\)</span>为确定性策略而<span class="math inline">\(\pi^{&#39;}\)</span>是<span class="math inline">\(\pi\)</span>的<span class="math inline">\(\epsilon\)</span>-贪心策略，则<span class="math inline">\(\pi\left(x_{i}, a_{i}\right)\)</span>对于<span class="math inline">\(a_i=\pi(x_i)\)</span>始终为1，<span class="math inline">\(\pi^{\prime}\left(x_{i},
a_{i}\right)\)</span>为<span class="math inline">\(\frac{\epsilon}{|A|}\)</span>或<span class="math inline">\(1-\epsilon+\frac{\epsilon}{|A|}\)</span>，于是就能对策略<span class="math inline">\(\pi\)</span>进行评估了，下图给出了异策略（off-policy）蒙特卡罗强化学习算法的伪代码：</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.png"></p>
<h2 id="时序差分学习temporal-difference-learning">时序差分学习（Temporal
Difference Learning）</h2>
<p>　　基于动态规划的策略迭代和值迭代算法在每执行一步策略后就进行值函数更新两者相比，蒙特卡罗强化学习算法的效率低得多，因为蒙特卡罗强化学习算法没有充分利用强化学习任务的MDP结构，它通过考虑采样轨迹，克服了模型未知给策略估计造成的困难，它需在完成一个采样轨迹后再更新策略的值估计。而时序差分学习则结合了动态规划与蒙特卡罗方法的思想，能做到更高效的免模型学习。<br>
　　蒙特卡罗强化学习算法的本质是通过多次尝试后求平均来作为期望累积奖赏的近似，但它在求平均时是批处理式进行的，即在一个完整的采样轨迹完成后再对所有的状态动作对进行更新，实际上这个更新过程能增量式进行。对于状态-动作对<span class="math inline">\((x,a)\)</span>，不妨假定基于<span class="math inline">\(t\)</span>个采样已估计出值函数<span class="math inline">\(Q_{t}^{\pi}(x, a)=\frac{1}{t} \sum_{i=1}^{t}
r_{i}\)</span>，则在得到第<span class="math inline">\(t+1\)</span>个采样<span class="math inline">\(r_{t+1}\)</span>时，类似式(2)有： <span class="math display">\[
Q_{t+1}^{\pi}(x, a)=Q_{t}^{\pi}(x,
a)+\frac{1}{t+1}\left(r_{t+1}-Q_{t}^{\pi}(x, a)\right)
\]</span> 　　这也是一个增量式的，将<span class="math inline">\(\frac{1}{t+1}\)</span>替换为系数<span class="math inline">\(\alpha_{t+1}\)</span>，则可将增量项写作<span class="math inline">\(\alpha_{t+1}\left(r_{t+1}-Q_{t}^{\pi}(x,
a)\right)\)</span>。在实践中通常令<span class="math inline">\(\alpha_t\)</span>为一个较小的正数值<span class="math inline">\(\alpha\)</span>，若将<span class="math inline">\(Q_{t}^{\pi}(x,
a)\)</span>展开为每步累积奖赏之和，则可看出系数之和为1，即令<span class="math inline">\(\alpha_t=\alpha\)</span>不会影响<span class="math inline">\(Q_t\)</span>是累积奖赏之和这一性质，更新步长<span class="math inline">\(\alpha\)</span>越大，则越靠后的累积奖赏越重要。<br>
　　以<span class="math inline">\(\gamma\)</span>折扣累积奖赏为例，利用动态规划方法且考虑到模型未知时使用状态动作值函数更方便，由式(7)有：
<span class="math display">\[
\begin{aligned} Q^{\pi}(x, a) &amp;=\sum_{x^{\prime} \in X} P_{x
\rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma
V^{\pi}\left(x^{\prime}\right)\right) \\ &amp;=\sum_{x^{\prime} \in X}
P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow
x^{\prime}}^{a}+\gamma \sum_{a^{\prime} \in A} \pi\left(x^{\prime},
a^{\prime}\right) Q^{\pi}\left(x^{\prime}, a^{\prime}\right)\right)
\end{aligned}
\]</span> 　　通过增量求和可得，其中<span class="math inline">\(x^{&#39;}\)</span>是前一次在状态<span class="math inline">\(x\)</span>执行动作<span class="math inline">\(a\)</span>后转移到的状态，<span class="math inline">\(a^{&#39;}\)</span>是策略<span class="math inline">\(\pi\)</span>在<span class="math inline">\(x^{&#39;}\)</span>上选择的动作： <span class="math display">\[
Q_{t+1}^{\pi}(x, a)=Q_{t}^{\pi}(x, a)+\alpha\left(R_{x \rightarrow
x^{\prime}}^{a}+\gamma Q_{t}^{\pi}\left(x^{\prime},
a^{\prime}\right)-Q_{t}^{\pi}(x, a)\right) \qquad(19)
\]</span>
　　使用式(19)，每执行一步策略就更新一次值函数估计，于是得到下图的Sarsa算法，该算法由于每次更新值函数需知道前一步的状态（state）、前一步的动作（action）、奖赏值（reward）、当前状态（state）、将要执行的动作（action）。Sarsa是一个同策略算法，算法中评估和执行的均为<span class="math inline">\(\epsilon\)</span>-贪心策略。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.png"></p>
<p>　　将Sarsa修改为异策略算法，则得到下图描述的<span class="math inline">\(Q\)</span>学习（Q-learning）算法，该算法评估的是<span class="math inline">\(\epsilon\)</span>-贪心策略，而执行的是原始策略。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.png"></p>
<h1 id="值函数近似value-function-approximation">值函数近似（value
function approximation）</h1>
<p>　　前面我们一直假定强化学习任务是在有限状态空间上进行，而现实强化学习任务所面临的状态空间往往是连续的，有无穷多个状态。<br>
　　一个直接的想法是对状态空间进行离散化，将连续状态空间转化为有限离散状态空间，然而如何有效地对状态空间进行离散化是一个难题，尤其是在对状态空间进行探索之前。实际上，我们不妨直接对连续状态空间的值函数进行学习。假定状态空间为<span class="math inline">\(n\)</span>维实数空间<span class="math inline">\(X=\mathbb{R}^{n}\)</span>，先考虑简单情形，即值函数能表达为状态的线性函数：
<span class="math display">\[
V_{\boldsymbol{\theta}}(\boldsymbol{x})=\boldsymbol{\theta}^{\mathrm{T}}
\boldsymbol{x} \qquad(20)
\]</span> 　　其中<span class="math inline">\(\boldsymbol{x}\)</span>为状态向量，<span class="math inline">\(\boldsymbol{\theta}\)</span>为参数向量。由于此时的值函数难以像有限状态那样精确记录每个状态的值，因此这样值函数的求解被称为值函数近似。<br>
　　我们希望通过式(20)学得的值函数尽可能近似真实值函数<span class="math inline">\(V^{\pi}\)</span>，近似程度常用最小二乘误差来度量：
<span class="math display">\[
E_{\boldsymbol{\theta}}=\mathbb{E}_{\boldsymbol{x} \sim
\pi}\left[\left(V^{\pi}(\boldsymbol{x})-V_{\boldsymbol{\theta}}(\boldsymbol{x})\right)^{2}\right]
\]</span> 　　其中<span class="math inline">\(\mathbb{E}_{\boldsymbol{x}
\sim \pi}\)</span>表示由策略<span class="math inline">\(\pi\)</span>所采样而得的状态上的期望。<br>
　　为了使误差最小化采用梯度下降法对误差求负导数： <span class="math display">\[
\begin{aligned}-\frac{\partial E_{\boldsymbol{\theta}}}{\partial
\boldsymbol{\theta}} &amp;=\mathbb{E}_{\boldsymbol{x} \sim
\pi}\left[2\left(V^{\pi}(\boldsymbol{x})-V_{\boldsymbol{\theta}}(\boldsymbol{x})\right)
\frac{\partial V_{\boldsymbol{\theta}}(\boldsymbol{x})}{\partial
\boldsymbol{\theta}}\right] \\ &amp;=\mathbb{E}_{\boldsymbol{x} \sim
\pi}\left[2\left(V^{\pi}(\boldsymbol{x})-V_{\boldsymbol{\theta}}(\boldsymbol{x})\right)
\boldsymbol{x}\right] \end{aligned}
\]</span> 　　于是可得到对于单个样本的更新规则： <span class="math display">\[
\boldsymbol{\theta}=\boldsymbol{\theta}+\alpha\left(V^{\pi}(\boldsymbol{x})-V_{\boldsymbol{\theta}}(\boldsymbol{x})\right)
\boldsymbol{x}
\]</span> 　　我们并不知道策略的真实值函数<span class="math inline">\(V^{\pi}\)</span>，但可借助时序差分学习基于<span class="math inline">\(V^{\pi}(\boldsymbol{x})=r+\gamma
V^{\pi}\left(\boldsymbol{x}^{\prime}\right)\)</span>用当前估计的值函数代替真实值函数，即：
<span class="math display">\[
\begin{aligned} \boldsymbol{\theta}
&amp;=\boldsymbol{\theta}+\alpha\left(r+\gamma
V_{\boldsymbol{\theta}}\left(\boldsymbol{x}^{\prime}\right)-V_{\boldsymbol{\theta}}(\boldsymbol{x})\right)
\boldsymbol{x} \\ &amp;=\boldsymbol{\theta}+\alpha\left(r+\gamma
\boldsymbol{\theta}^{\mathrm{T}}
\boldsymbol{x}^{\prime}-\boldsymbol{\theta}^{\mathrm{T}}
\boldsymbol{x}\right) \boldsymbol{x} \end{aligned}
\]</span> 　　其中<span class="math inline">\(\boldsymbol{x}^{\prime}\)</span>是下一时刻的状态。<br>
　　需注意的是，在时序差分学习中需要状态-动作值函数以便获取策略。我们可以令<span class="math inline">\(\boldsymbol{\theta}\)</span>作用于表示状态和动作的联合向量上，例如给状态向量增加一维用于存放动作编号，即将式(20)中的<span class="math inline">\(\boldsymbol{x}\)</span>替换为<span class="math inline">\((\boldsymbol{x};a)\)</span>，另一种做法是用0/1对动作选择进行编码得到向量<span class="math inline">\(\boldsymbol{a}=(0 ; \ldots ; 1 ; \ldots ;
0)\)</span>，其中“1”表示该动作被选择，再将状态向量与其合并得到<span class="math inline">\((\boldsymbol{x};a)\)</span>，用于替换式(10)中的<span class="math inline">\(\boldsymbol{x}\)</span>。这样就使得线性近似的对象为状态-动作值函数。<br>
　　下图是线性值函数近似Sarsa算法，类似地可得到线性值函数近似<span class="math inline">\(Q\)</span>学习算法。显然，可以容易地用其他学习方法来代替式(10)中的线性学习器，例如通过引入核方法实现非线胜值函数近似。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/11.png"></p>
<h1 id="模仿学习imitation-learning">模仿学习（Imitation Learning）</h1>
<p>　　在强化学习的经典任务设置中，机器所能获得的反馈信息仅有多步决策后的累积奖赏，但在现实任务中，往往能得到人类专家的决策过程范例，例如在AlphaGo能学习人类经典的棋谱和经典的范例，这就称为模仿学习。</p>
<h2 id="直接模仿学习">直接模仿学习</h2>
<p>　　强化学习任务中多步决策的搜索空间巨大，基于累积奖赏来学习很多步之前的合适决策非常困难，而直接模仿人类专家的状态-动作对可显著缓解这一困难，这称为直接模仿学习。<br>
　　假定我们获得了一批人类专家的决策轨迹数据<span class="math inline">\(\left\{\tau_{1}, \tau_{2}, \ldots,
\tau_{m}\right\}\)</span>，每条轨迹包含状态和动作序列，其中<span class="math inline">\(n_i\)</span>为第<span class="math inline">\(i\)</span>条轨迹中的转移次数： <span class="math display">\[
\tau_{i}=\left\langle s_{1}^{i}, a_{1}^{i}, s_{2}^{i}, a_{2}^{i},
\ldots, s_{n_{i}+1}^{i}\right\rangle
\]</span>
　　有了这样的数据，就相当于告诉机器在什么状态下应选择什么动作，于是可利用监督学习来学得符合人类专家决策轨迹数据的策略。<br>
　　我们可将所有轨迹上的所有状态-动作对抽取出来，构造出一个新的数据集合:
<span class="math display">\[
D=\left\{\left(s_{1}, a_{1}\right),\left(s_{2}, a_{2}\right),
\ldots,\left(s \sum_{i=1}^{m} n_{i}, a_{\sum_{i=1}^{m}
n_{i}}\right)\right\}
\]</span>
　　即把状态作为特征，动作作为标记。然后，对这个新构造出的数据集合<span class="math inline">\(D\)</span>使用分类（对于离散动作）或回归（对于连续动作）算法即可学得策略模型。学得的这个策略模型可作为机器进行强化学习的初始策略，再通过强化学习方法基于环境反馈进行改进，从而获得更好的策略。</p>
<h2 id="逆强化学习inverse-reinforcement-learning">逆强化学习（inverse
reinforcement learning）</h2>
<p>　　在很多任务中，设计奖赏函数往往相当困难，从人类专家提供的范例数据中反推出奖赏函数有助于解决该问题，这就是逆强化学习。在逆强化学习中，我们知道状态空间<span class="math inline">\(X\)</span>、动作空间<span class="math inline">\(A\)</span>，并且与直接模仿学习类似，有一个决策轨迹数据集<span class="math inline">\(\left\{\tau_{1}, \tau_{2}, \ldots,
\tau_{m}\right\}\)</span>。逆强化学习的基本思想是：欲使机器做出与范例一致的行为，等价于在某个奖赏函数的环境中求解最优策略，该最优策略所产生的轨迹与范例数据一致换言之，我们要寻找某种奖赏函数使得范例数据是最优的，然后即可使用这个奖赏函数来训练强化学习策略。<br>
　　不妨假设奖赏函数能表达为状态特征的线性函数，即<span class="math inline">\(R(\boldsymbol{x})=\boldsymbol{w}^{\mathrm{T}}
\boldsymbol{x}\)</span>。于是，策略<span class="math inline">\(\pi\)</span>的累积奖赏可写为状态向量加权和的期望与系数<span class="math inline">\(\boldsymbol{w}\)</span>的内积： <span class="math display">\[
\begin{aligned}
\rho^{\pi}&amp;=\mathbb{E}\left[\sum_{t=0}^{+\infty} \gamma^{t}
R\left(\boldsymbol{x}_{t}\right) |
\pi\right]=\mathbb{E}\left[\sum_{t=0}^{+\infty} \gamma^{t}
\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{t} | \pi\right] \\
&amp;=\boldsymbol{w}^{\mathrm{T}} \mathbb{E}\left[\sum_{t=0}^{+\infty}
\gamma^{t} \boldsymbol{x}_{t} | \pi\right]
\end{aligned}
\]</span> 　　将状态向量的期望<span class="math inline">\(\mathbb{E}\left[\sum_{t=0}^{+\infty} \gamma^{t}
\boldsymbol{x}_{t} | \pi\right]\)</span>简写为<span class="math inline">\(\overline{\boldsymbol{x}}^{\pi}\)</span>。注意到获得<span class="math inline">\(\overline{\boldsymbol{x}}^{\pi}\)</span>需求取期望，我们可使用蒙特长罗方法通过采样来近似期望，而范例轨迹数据集恰可看作最优策略的一个采样，于是，可将每条范例轨迹上的状态加权求和再平均，记为<span class="math inline">\(\overline{\boldsymbol{x}}^{*}\)</span>，对于最优奖赏函数<span class="math inline">\(R(\boldsymbol{x})=\boldsymbol{w}^{* \mathrm{T}}
\boldsymbol{x}\)</span>和任意其他策略产生的<span class="math inline">\(\overline{\boldsymbol{x}}^{\pi}\)</span>，有：
<span class="math display">\[
\boldsymbol{w}^{* \mathrm{T}}
\overline{\boldsymbol{x}}^{*}-\boldsymbol{w}^{* \mathrm{T}}
\overline{\boldsymbol{x}}^{\pi}=\boldsymbol{w}^{*
\mathrm{T}}\left(\overline{\boldsymbol{x}}^{*}-\overline{\boldsymbol{x}}^{\pi}\right)
\geqslant 0
\]</span> 　　若能对所有策略计算出<span class="math inline">\(\left(\overline{\boldsymbol{x}}^{*}-\overline{\boldsymbol{x}}^{\pi}\right)\)</span>，即可解出：
<span class="math display">\[
\begin{array}{c}{\boldsymbol{w}^{*}=\underset{\boldsymbol{w}}{\arg \max
} \min _{\pi}
\boldsymbol{w}^{\mathrm{T}}\left(\overline{\boldsymbol{x}}^{*}-\overline{\boldsymbol{x}}^{\pi}\right)}
\\ {\text { s.t. }\|\boldsymbol{w}\| \leqslant 1}\end{array}
\]</span>
　　显然，我们难以获得所有策略，一个较好的办法是从随机策略开始，迭代地求解更好的奖赏函数，基于奖赏函数获得更好的策略，直至最终获得最符合范例轨迹数据集的奖赏函数和策略，下图是算法的伪代码。</p>
<p><img src="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/12.png"></p>
<h1 id="refer">Refer</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/26708119/">机器学习</a></li>
</ul>
<h1 id="相关内容">相关内容</h1>
<ul>
<li><a href="http://chengfeng96.com/blog/2019/12/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">机器学习基础笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2018/12/15/%E5%AF%B9%E6%95%B0%E5%87%A0%E7%8E%87%E5%9B%9E%E5%BD%92%EF%BC%88Logistic-Regression%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（一）-
对数几率回归（Logistic Regression）笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2018/12/22/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%EF%BC%88Linear-Discriminant-Analysis%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（二）-
线性判别分析（Linear Discriminant Analysis）笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/03/14/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Principle-Component-Analysis-PCA%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（三）-
主成分分析（Principle Component Analysis, PCA）笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/04/05/%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88Decision-Tree%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（四）-
决策树（Decision Tree）笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/04/10/BP%E7%AE%97%E6%B3%95%E7%9A%84%E6%8E%A8%E5%AF%BC/">机器学习基础（五）-
BP 算法推导</a></li>
<li><a href="http://chengfeng96.com/blog/2019/04/18/SVM%E7%AC%94%E8%AE%B0/">机器学习基础（六）-
SVM 笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/05/13/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习基础（七）-
集成学习笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/05/17/%E8%81%9A%E7%B1%BB%E7%AC%94%E8%AE%B0/">机器学习基础（八）-
聚类笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/05/19/%E5%A4%9A%E7%BB%B4%E7%BC%A9%E6%94%BEMDS%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95/">机器学习基础（九）-
多维缩放笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/05/21/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%AC%94%E8%AE%B0/">机器学习基础（十）-
特征选择笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/05/26/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习基础（十一）-
半监督学习笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/06/20/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/">机器学习基础（十三）-
隐马尔可夫模型笔记</a></li>
<li><a href="http://chengfeng96.com/blog/2019/05/04/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%AC%94%E8%AE%B0/">机器学习基础（十四）-
贝叶斯分类器笔记</a></li>
</ul>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习基础（十二）- 强化学习笔记</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页"></a></p>
        <p><span>发布时间:</span>2019-06-08, 21:47:50</p>
        <p><span>最后更新:</span>2020-06-08, 13:53:07</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="机器学习基础（十二）- 强化学习笔记">http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</a>
            <span class="copy-path" data-clipboard-text="原文: http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/　　作者: " title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/blog/2019/06/20/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/">
                    机器学习基础（十三）- 隐马尔可夫模型笔记
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/blog/2019/05/26/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                    机器学习基础（十一）- 半监督学习笔记
                </a>
            </div>
        
    </nav>

  
  
    
    <div style="padding: 0; margin: 20px auto; width: 90%; text-align: center;">
      <br>
      <div>坚持原创技术分享，您的支持将鼓励我继续创作，π（3.14）元就够啦！</div>
      <br>
      <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
        <div class="btn btn-pay">打赏支持</div>
      </button>
      <br>
      <br>
      <div id="QR" style="display: none;">
        
          <div id="wechat" style="display: inline-block;">
            <img id="wechat_qr" src="/img/wechat.jpg" alt=" WeChat Pay"/>
            <p>微信打赏</p>
          </div>
        
        
          <div id="alipay" style="display: inline-block">
            <img id="alipay_qr" src="/img/alipay.jpg" alt=" Alipay"/>
            <p>支付宝打赏</p>
          </div>
        
        <br>
        <br>
      </div>
    </div>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0reinforcement-learning"><span class="toc-number">2.</span> <span class="toc-text">强化学习（Reinforcement
Learning）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#k-%E6%91%87%E8%87%82%E8%B5%8C%E5%8D%9A%E6%9C%BA"><span class="toc-number">3.</span> <span class="toc-text">\(K\)-摇臂赌博机</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A2%E7%B4%A2-%E5%88%A9%E7%94%A8%E7%AA%98%E5%A2%83exploration-exploitation-dilemma"><span class="toc-number">3.1.</span> <span class="toc-text">探索-利用窘境（Exploration-Exploitation
dilemma）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#epsilon-%E8%B4%AA%E5%BF%83epsilon-greedy"><span class="toc-number">3.2.</span> <span class="toc-text">\(\epsilon\)-贪心（epsilon-Greedy）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#softmax"><span class="toc-number">3.3.</span> <span class="toc-text">Softmax</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%89%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0model-based-learning"><span class="toc-number">4.</span> <span class="toc-text">有模型的学习（model-based
learning）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%E8%AF%84%E4%BC%B0"><span class="toc-number">4.1.</span> <span class="toc-text">策略评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%E6%94%B9%E8%BF%9B"><span class="toc-number">4.2.</span> <span class="toc-text">策略改进</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3policy-iteration%E4%B8%8E%E5%80%BC%E8%BF%AD%E4%BB%A3value-iteration"><span class="toc-number">4.3.</span> <span class="toc-text">策略迭代（policy
iteration）与值迭代（value iteration）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%8D%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0model-free-learning"><span class="toc-number">5.</span> <span class="toc-text">免模型学习（model-free
learning）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0monte-carlo-learning"><span class="toc-number">5.1.</span> <span class="toc-text">蒙特卡罗强化学习（Monte
Carlo Learning）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E5%AD%A6%E4%B9%A0temporal-difference-learning"><span class="toc-number">5.2.</span> <span class="toc-text">时序差分学习（Temporal
Difference Learning）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%80%BC%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BCvalue-function-approximation"><span class="toc-number">6.</span> <span class="toc-text">值函数近似（value
function approximation）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0imitation-learning"><span class="toc-number">7.</span> <span class="toc-text">模仿学习（Imitation Learning）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E6%A8%A1%E4%BB%BF%E5%AD%A6%E4%B9%A0"><span class="toc-number">7.1.</span> <span class="toc-text">直接模仿学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%86%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0inverse-reinforcement-learning"><span class="toc-number">7.2.</span> <span class="toc-text">逆强化学习（inverse
reinforcement learning）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#refer"><span class="toc-number">8.</span> <span class="toc-text">Refer</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9"><span class="toc-number">9.</span> <span class="toc-text">相关内容</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"机器学习基础（十二）- 强化学习笔记　| 零一人生　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    
        <section id="comments">
    <style> aside.comment-bar { margin: auto 30px; }</style>
    <div id="disqus_thread"></div>
    <script>
        var disqus_config = function(){
            this.page.url = 'http://chengfeng96.com/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/';
            this.page.identifier = 'blog/2019/06/08/强化学习笔记/';
        };
        var loadComment = function(){
            var d = document, s = d.createElement('script');
            s.src = '//HelloHazzaCheng.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        }
    </script>
    
    <script> loadComment(); </script>

</section>


    




    <div class="scroll" id="post-nav-button">
        
            <a href="/blog/2019/06/20/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/" title="上一篇: 机器学习基础（十三）- 隐马尔可夫模型笔记">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/blog/2019/05/26/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="下一篇: 机器学习基础（十一）- 半监督学习笔记">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/blog/2021/11/21/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89-PC-DARTS/">NAS 学习笔记（二十）- PC-DARTS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2021/11/17/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B9%9D%EF%BC%89-ProxylessNAS/">NAS 学习笔记（十九）- ProxylessNAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2021/04/06/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89-DARTS-PT/">NAS 学习笔记（十八）- DARTS+PT</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/12/04/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%83%EF%BC%89-SNAS/">NAS 学习笔记（十七）- SNAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/11/09/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E5%85%AD%EF%BC%89-NoisyDARTS/">NAS 学习笔记（十六）- NoisyDARTS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/11/06/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89-P-DARTS/">NAS 学习笔记（十五）- P-DARTS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/27/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89-GDBT-NAS/">NAS 学习笔记（十四）- GDBT-NAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/24/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89-NASP/">NAS 学习笔记（十三）- NASP</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/18/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89-SemiNAS/">NAS 学习笔记（十二）- SemiNAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/16/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89-GreedyNAS/">NAS 学习笔记（十一）- GreedyNAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/13/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89-Fair-DARTS/">NAS 学习笔记（十）- Fair DARTS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/11/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89-FairNAS/">NAS 学习笔记（九）- FairNAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/07/09/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89-SPOS/">NAS 学习笔记（八）- SPOS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/06/23/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89-NAO/">NAS 学习笔记（七）- NAO</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/06/16/XGBoost-%E5%92%8C-Lightgbm-%E7%AC%94%E8%AE%B0/">XGBoost 和 Lightgbm 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/28/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89-%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E7%9A%84%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AD%96%E7%95%A5/">强化学习笔记（八）- 连续空间的确定性策略</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/24/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89-%E8%B5%84%E6%A0%BC%E8%BF%B9/">强化学习笔记（七）- 资格迹</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/21/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89-%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6/">强化学习笔记（六）- 策略梯度</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/19/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89-%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BC%E6%96%B9%E6%B3%95/">强化学习笔记（五）- 函数近似方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/16/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89-%E6%97%B6%E5%BA%8F%E5%B7%AE%E5%88%86%E5%AD%A6%E4%B9%A0/">强化学习笔记（四）- 时序差分学习</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89-%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%96%B9%E6%B3%95/">强化学习笔记（三）- 蒙特卡罗方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/14/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%96%B9%E6%B3%95/">强化学习笔记（二）- 动态规划方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2020/02/11/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89-Markov-%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B%E6%A8%A1%E5%9E%8B/">强化学习笔记（一）- Markov 决策过程模型</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/12/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">机器学习基础笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/12/02/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89-Evolution-NAS/">NAS 学习笔记（六）- Evolution NAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/30/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89-DARTS/">NAS 学习笔记（五）- DARTS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/28/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89-One-Shot-Architecture-Search/">NAS 学习笔记（四）- One-Shot Architecture Search</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/27/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89-ENAS/">NAS 学习笔记（三）- ENAS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/26/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89-SMASH/">NAS 学习笔记（二）- SMASH</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/26/NAS-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89-NASNet/">NAS 学习笔记（一）- NASNet</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/19/BOHB-%E7%AC%94%E8%AE%B0/">AutoML HPO 学习笔记（五）- BOHB</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/18/Hyeperband-%E7%AC%94%E8%AE%B0/">AutoML HPO 学习笔记（四）- Hyeperband</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/15/SMAC-%E7%AC%94%E8%AE%B0/">AutoML HPO 学习笔记（三）- SMAC</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/13/Hyperopt-%E5%92%8C-TPE-%E7%AC%94%E8%AE%B0/">AutoML HPO 学习笔记（二）- Hyperopt 和 TPE</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/11/06/Ensemble-Selection-%E7%AC%94%E8%AE%B0/">Ensemble Selection 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/09/08/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/">AutoML HPO 学习笔记（一）- 贝叶斯优化</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/07/26/%E8%AF%BB%E3%80%8A%E8%87%AA%E7%A7%81%E7%9A%84%E5%9F%BA%E5%9B%A0%E3%80%8B-%E7%88%B6%E6%AF%8D%E4%B8%BA%E5%95%A5%E6%80%BB%E6%98%AF%E6%97%A0%E7%A7%81%E7%9A%84/">读《自私的基因》--父母为啥总是无私的</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/06/20/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/">机器学习基础（十三）- 隐马尔可夫模型笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/06/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习基础（十二）- 强化学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/05/26/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习基础（十一）- 半监督学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/05/21/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%AC%94%E8%AE%B0/">机器学习基础（十）- 特征选择笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/05/19/%E5%A4%9A%E7%BB%B4%E7%BC%A9%E6%94%BEMDS%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95/">机器学习基础（九）- 多维缩放笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/05/17/%E8%81%9A%E7%B1%BB%E7%AC%94%E8%AE%B0/">机器学习基础（八）- 聚类笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/05/13/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">机器学习基础（七）- 集成学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/05/04/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%AC%94%E8%AE%B0/">机器学习基础（十四）- 贝叶斯分类器笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/28/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E7%AC%94%E8%AE%B0/">马尔可夫链笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/25/%E4%BC%AF%E5%8A%AA%E5%88%A9%E8%BF%87%E7%A8%8B%E5%92%8C%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/">伯努利过程和泊松过程笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/21/%E7%BB%8F%E5%85%B8%E7%BB%9F%E8%AE%A1%E6%8E%A8%E6%96%AD%E7%AC%94%E8%AE%B0/">经典统计推断笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/18/SVM%E7%AC%94%E8%AE%B0/">机器学习基础（六）- SVM 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/11/%E8%AF%BB%E3%80%8A%E8%8F%8A%E4%B8%8E%E5%88%80%E3%80%8B-%E6%9C%89%E7%82%B9%E7%9F%9B%E7%9B%BE%E7%9A%84%E6%97%A5%E6%9C%AC%E4%BA%BA/">读《菊与刀》--有点矛盾的日本人</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/10/BP%E7%AE%97%E6%B3%95%E7%9A%84%E6%8E%A8%E5%AF%BC/">机器学习基础（五）- BP 算法推导</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/10/%E6%9E%81%E9%99%90%E7%90%86%E8%AE%BA%E7%AC%94%E8%AE%B0/">极限理论笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/06/%E5%9F%BA%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%96%B9%E6%B3%95%E7%9A%84%E5%B8%B8%E8%A7%81%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95/">基于贝叶斯方法的常见估计方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/04/05/%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88Decision-Tree%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（四）- 决策树（Decision Tree）笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/20/Spark-Shuffle%E8%B0%83%E7%A0%94%E7%AC%94%E8%AE%B0/">Spark Shuffle调研笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/18/%E8%AF%BB%E3%80%8A%E6%9E%AA%E7%82%AE%E3%80%81%E7%97%85%E8%8F%8C%E4%B8%8E%E9%92%A2%E9%93%81%E3%80%8B-%E9%83%BD%E6%98%AF%E8%80%81%E5%A4%A9%E7%88%B7%E8%B5%8F%E7%9A%84%E9%A5%AD/">读《枪炮、病菌与钢铁》--都是老天爷赏的饭</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/17/%E5%B8%B8%E8%A7%81%E8%BF%9E%E7%BB%AD%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%EF%BC%8C%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE/">常见连续随机变量的概率密度函数，均值和方差</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/14/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88Principle-Component-Analysis-PCA%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（三）- 主成分分析（Principle Component Analysis, PCA）笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/03/06/%E5%B8%B8%E8%A7%81%E7%A6%BB%E6%95%A3%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%88%86%E5%B8%83%E5%88%97%EF%BC%8C%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE/">常见离散随机变量的分布列，均值和方差</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/25/%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E6%A6%82%E7%8E%87%E9%97%AE%E9%A2%98/">一些有趣的概率问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/23/%E8%AF%BB%E3%80%8A%E8%8D%92%E8%AF%9E%E5%8C%BB%E5%AD%A6%E5%8F%B2%E3%80%8B--%E5%8C%BB%E5%AD%A6%E7%9A%84%E8%BF%9B%E6%AD%A5/">读《荒诞医学史》--医学的进步</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/16/%E8%AF%BB%E3%80%8A%E6%B8%85%E6%95%99%E5%BE%92%E7%9A%84%E7%A4%BC%E7%89%A9%E3%80%8B--%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%96%87%E5%8C%96%E6%98%AF%E6%B8%85%E6%95%99%E5%BE%92%E7%9A%84%E7%B2%BE%E7%A5%9E%E5%90%97/">读《清教徒的礼物》--工程师文化是清教徒的精神吗</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/11/%E8%AF%BB%E3%80%8A%E7%A9%B7%E6%9F%A5%E7%90%86%E5%AE%9D%E5%85%B8%E3%80%8B--%E8%B7%A8%E5%AD%A6%E7%A7%91%E7%9A%84%E7%9F%A5%E8%AF%86/">读《穷查理宝典》--跨学科的知识</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/04/%E8%AF%BB%E3%80%8A%E5%B9%B3%E9%9D%A2%E5%9B%BD%E3%80%8B--%E5%9B%9B%E7%BB%B4%E4%B8%96%E7%95%8C%E7%9A%84%E2%80%9C%E4%BA%BA%E4%BB%AC%E2%80%9D%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85%E6%88%91%E4%BB%AC%E5%91%A2/">读《平面国》--四维世界的“人们”如何看待我们呢</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/02/%E5%AF%B9%E4%BA%8E%E6%A2%AF%E5%BA%A6%E7%9A%84%E7%90%86%E8%A7%A3/">对于梯度的理解</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/02/01/%E8%AF%BB%E3%80%8A5%E5%88%86%E9%92%9F%E5%95%86%E5%AD%A6%E9%99%A2%E2%80%A2%E5%95%86%E4%B8%9A%E7%AF%87%E3%80%8B--%E5%AD%A6%E7%82%B9%E5%95%86%E4%B8%9A%E5%A5%97%E8%B7%AF/">读《5分钟商学院•商业篇》--学点商业套路</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/31/Yarn%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/">Yarn 基本架构</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/31/%E8%AF%BB%E3%80%8A%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2%E3%80%8B--%E6%99%BA%E4%BA%BA%E7%9A%84%E8%99%9A%E6%9E%84%E7%8E%B0%E5%AE%9E/">读《人类简史》--智人的虚构现实</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/30/%E4%B8%80%E4%BA%9BHadoop%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E6%96%B9%E6%B3%95/">一些 Hadoop 性能调优的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/30/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B9%8B%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/">线性代数之奇异值分解及其应用</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/29/Hadoop-MapReduce%E4%B8%ADTask%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/">Hadoop MapReduce中Task的执行流程</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/27/Hadoop%E7%9A%84%E4%BB%BB%E5%8A%A1%E6%8E%A8%E6%B5%8B%E6%89%A7%E8%A1%8C%E7%AE%97%E6%B3%95/">Hadoop的任务推测执行算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/25/%E4%B8%BASpark-SQL%E6%B7%BB%E5%8A%A0%E5%8E%9F%E7%94%9F%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%AD%E6%B3%95/">为Spark SQL添加原生自定义语法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/19/Hadoop%20MRv1%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/">Hadoop MRv1基本架构</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/18/%E8%AF%BB%E3%80%8A%E6%97%A0%E6%95%8C%E8%88%B0%E9%98%9F%E3%80%8B--%E7%9B%B8%E4%BF%A1%E2%80%9C%E5%A5%87%E8%BF%B9%E2%80%9D%E7%9A%84%E2%80%9C%E6%97%A0%E6%95%8C%E2%80%9D%E8%88%B0%E9%98%9F/">读《无敌舰队》--相信“奇迹”的“无敌”舰队</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/17/%E8%AF%BB%E3%80%8A%E8%96%9B%E5%85%86%E4%B8%B0%E7%BB%8F%E6%B5%8E%E5%AD%A6%E8%AE%B2%E4%B9%89%E3%80%8B--%E4%BA%BA%E4%BA%BA%E9%83%BD%E5%BA%94%E8%AF%A5%E5%AD%A6%E7%82%B9%E7%BB%8F%E6%B5%8E%E5%AD%A6/">读《薛兆丰经济学讲义》--人人都应该学点经济学</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2019/01/05/%E8%AF%BB%E3%80%8A%E5%BE%AE%E8%A7%82%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%AE%8F%E8%A7%82%E8%A1%8C%E4%B8%BA%E3%80%8B--%E4%BA%BA%E4%BB%A5%E7%BE%A4%E5%88%86%EF%BC%8C%E4%BA%92%E7%9B%B8%E4%BE%9D%E8%B5%96/">读《微观动机与宏观行为》--人以群分，互相依赖</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/12/29/%E8%AF%BB%E3%80%8A%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E4%B8%8D%E7%84%A6%E8%99%91%E3%80%8B--%E4%B8%93%E6%B3%A8%E6%88%98%E8%83%9C%E7%84%A6%E8%99%91/">读《如何才能不焦虑》--专注战胜焦虑</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/12/22/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%EF%BC%88Linear-Discriminant-Analysis%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（二）- 线性判别分析（Linear Discriminant Analysis）笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/12/21/%E8%AF%BB%E3%80%8A%E4%BA%B2%E5%AF%86%E5%85%B3%E7%B3%BB%E3%80%8B--%E4%BA%B2%E5%AF%86%E5%85%B3%E7%B3%BB%E7%9A%84%E5%A5%97%E8%B7%AF/">读《亲密关系》--亲密关系的套路</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/12/15/%E5%AF%B9%E6%95%B0%E5%87%A0%E7%8E%87%E5%9B%9E%E5%BD%92%EF%BC%88Logistic-Regression%EF%BC%89%E6%B5%85%E8%B0%88/">机器学习基础（一）- 对数几率回归（Logistic Regression）笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/12/07/%E8%AF%BB%E3%80%8A%E5%8D%8E%E6%9D%89%E8%AE%B2%E9%80%8F%E5%AD%99%E5%AD%90%E5%85%B5%E6%B3%95%E3%80%8B--%E4%BB%A5%E5%A5%87%EF%BC%88ji%EF%BC%89%E8%83%9C/">读《华杉讲透孙子兵法》--以奇(ji)胜</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/30/Hadoop%E5%92%8CSpark%E6%A0%B9%E6%8D%AElog4j%E8%87%AA%E5%AE%9A%E4%B9%89%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/">Hadoop和Spark根据log4j自定义日志输出</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/27/%E8%AF%BB%E3%80%8A%E6%B0%B8%E6%81%92%E7%9A%84%E8%BE%B9%E7%BC%98%E3%80%8B--%E5%B8%9D%E7%8E%8B%E6%81%AF%E4%BA%89/">读《永恒的边缘》--帝王息争</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/25/HDFS%E9%87%8C%E7%9A%84Hedged-Read%E6%BA%90%E7%A0%81%E4%BB%A5%E5%8F%8A%E5%B1%80%E9%99%90%E6%80%A7%E5%88%86%E6%9E%90/">HDFS里的Hedged Read源码以及局限性分析</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/22/HDFS%E9%87%8Cread-operation%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%BB%A5%E5%8F%8A%E8%AF%BB%E6%85%A2%E8%8A%82%E7%82%B9%E9%97%AE%E9%A2%98%E6%8E%A2%E7%A9%B6/">HDFS里read operation源码解析以及读慢节点问题探究</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/16/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/">Java 并发编程（十四）- 内存模型</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/15/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/">Java 并发编程（十三）- 非阻塞同步机制</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/13/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BAQS/">Java 并发编程（十二）- AQS</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/12/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%98%BE%E7%A4%BA%E9%94%81/">Java 并发编程（十一）- 显示锁</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/09/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%80%A7%E8%83%BD%E4%B8%8E%E5%8F%AF%E4%BC%B8%E7%BC%A9%E6%80%A7/">Java 并发编程（五）- 构建高效且可伸缩的结果缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/08/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%81%BF%E5%85%8D%E6%B4%BB%E8%B7%83%E6%80%A7%E7%9A%84%E5%8D%B1%E9%99%A9/">Java 并发编程（九）- 避免活跃性的危险</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/06/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/">Java 并发编程（八）- 线程池的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/04/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8F%96%E6%B6%88%E4%B8%8E%E5%85%B3%E9%97%AD/">Java 并发编程（七）- 取消与关闭</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/11/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BExecutor/">Java 并发编程（六）- Executor</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/24/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B%E4%B9%8B%E6%9E%84%E5%BB%BA%E9%AB%98%E6%95%88%E4%B8%94%E5%8F%AF%E4%BC%B8%E7%BC%A9%E7%9A%84%E7%BB%93%E6%9E%9C%E7%BC%93%E5%AD%98/">Java 并发编程（五）- 构建高效且可伸缩的结果缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/24/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9D%97/">Java 并发编程（四）- 基础构建模块</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/22/Spark%E9%87%8CHistroy-Server%E4%B8%A2task%EF%BC%8Cjob%E5%92%8CStage%E9%97%AE%E9%A2%98%E8%B0%83%E7%A0%94/">Spark里Histroy Server丢task，job和Stage问题调研</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/22/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F/">设计模式之观察者模式和发布-订阅模式</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/21/%E8%AF%BB%E3%80%8A%E6%BC%AB%E6%AD%A5%E5%8D%8E%E5%B0%94%E8%A1%97%E3%80%8B--%E5%9C%A8%E9%9A%8F%E6%9C%BA%E4%B8%AD%E6%BC%AB%E6%AD%A5%EF%BC%8C%E5%9C%A8%E9%9A%8F%E6%9C%BA%E4%B8%AD%E7%A8%B3%E5%AE%9A/">读《漫步华尔街》--在随机中漫步，在随机中稳定</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/21/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BB%84%E5%90%88/">Java 并发编程（三）- 对象的组合</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/18/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%85%B1%E4%BA%AB/">Java 并发编程（二）- 对象的共享</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/15/%E6%B5%85%E8%B0%88%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/">Java 并发编程（一）- 浅谈线程安全</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/14/Spark%E9%87%8C%E6%9C%89%E5%85%B3History-Server%E7%9A%84scheduler-delay%E7%9B%B8%E5%85%B3%E6%BA%90%E7%A0%81%E7%9A%84%E4%B8%80%E6%AC%A1%E8%B0%83%E7%A0%94/">Spark里有关History Server的scheduler delay相关源码的一次调研</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/11/JVM%E4%B8%AD%E7%9A%84%E5%88%86%E6%B4%BE%E6%9C%BA%E5%88%B6/">JVM 学习（十）- 分派机制</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/10/10/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/">JVM 学习（九）- 类加载机制</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/09/26/%E8%AF%BB%E3%80%8A%E4%B8%96%E7%95%8C%E7%9A%84%E5%87%9B%E5%86%AC%E3%80%8B--%E5%B9%B3%E6%B0%91%E7%9A%84%E6%88%98%E4%BA%89/">读《世界的凛冬》--平民的战争</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/08/05/%E8%B7%B3%E8%A1%A8%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0/">跳表简易实现</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/08/05/%E8%AF%BB%E3%80%8A%E5%B7%A8%E4%BA%BA%E7%9A%84%E9%99%A8%E8%90%BD%E3%80%8B--%E5%B9%B3%E6%B0%91%E7%9A%84%E5%B4%9B%E8%B5%B7/">读《巨人的陨落》--平民的崛起</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/08/04/LSM%E8%B0%83%E7%A0%94%E7%AC%94%E8%AE%B0/">LSM调研</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/07/29/B%E6%A0%91%E5%92%8CB-%E6%A0%91/">B树和B+树</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/07/28/Mysql%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95/">Mysql中的索引</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/07/19/BigTable%E8%B0%83%E7%A0%94%E7%AC%94%E8%AE%B0/">BigTable调研笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/06/19/%E8%AF%BB%E3%80%8A%E6%94%B9%E5%8F%98%E5%BF%83%E7%90%86%E5%AD%A6%E7%9A%8440%E9%A1%B9%E7%A0%94%E7%A9%B6%E3%80%8B--%E5%88%9D%E6%8E%A2%E5%BF%83%E7%90%86%E5%AD%A6/">读《改变心理学的40项研究》--初探心理学</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/06/13/%E6%9C%80%E5%A4%A7%E4%BA%8C%E5%88%86%E5%9B%BE%E5%8C%B9%E9%85%8D/">最大二分图匹配</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/06/12/%E8%8E%8E%E5%A3%AB%E6%AF%94%E4%BA%9A%E5%9B%BE%E4%B8%8E%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/">莎士比亚图与图数据库</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/06/12/%E6%9C%80%E5%B0%8F%E8%B4%B9%E7%94%A8%E6%9C%80%E5%A4%A7%E6%B5%81%E9%97%AE%E9%A2%98/">最小费用最大流问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/06/10/%E5%A2%9E%E5%B9%BF%E8%B7%AF%E5%AE%9A%E7%90%86%E5%92%8CEdmonds-Karp%E7%AE%97%E6%B3%95/">增广路定理和Edmonds-Karp算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/27/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/">GO 学习笔记（九）- 单元测试</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/26/%E5%88%A9%E7%94%A8BFS%EF%BC%8CDFS%EF%BC%8CA-%E8%A7%A3%E5%86%B3%E5%85%AB%E6%95%B0%E7%A0%81%E9%9A%BE%E9%A2%98/">利用BFS，DFS，A*算法解决八数码难题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/24/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84/">GO 学习笔记（八）- 反射</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/17/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B9%B6%E5%8F%91/">GO 学习笔记（七）- 并发</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/14/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%A5%E5%8F%A3/">GO 学习笔记（六）- 接口</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/13/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%96%B9%E6%B3%95/">GO 学习笔记（五）- 方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/11/Linux%E4%B8%8B%E9%81%BF%E5%85%8Drm%E8%AF%AF%E5%88%A0/">Linux下避免rm误删</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/06/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E6%8D%AE/">GO 学习笔记（四）- 数据</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/04/%E5%88%86%E5%B8%83%E5%BC%8F%E8%87%AA%E5%A2%9EID%E7%AE%97%E6%B3%95SnowFlake/">分布式自增ID算法SnowFlake</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/05/04/JVM%E8%B0%83%E4%BC%98%E6%A1%88%E4%BE%8B/">JVM 学习（八）- 调优案例</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/11/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/">JVM 学习（七）- 性能监控与故障处理工具</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/09/%E4%BD%8D%E8%BF%90%E7%AE%97%E6%8A%80%E5%B7%A7%E5%B0%8F%E7%BB%93/">位运算技巧小结</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/08/JVM%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5/">JVM 学习（六）- 内存分配与回收策略</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/08/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%87%BD%E6%95%B0/">GO 学习笔记（三）- 函数</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/08/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%A1%A8%E8%BE%BE%E5%BC%8F/">GO 学习笔记（二）- 表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/08/Go%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%98%E9%87%8F/">GO 学习笔记（一）- 变量</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/07/JVM%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/">JVM 学习（五）- 垃圾收集器</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/06/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/">设计模式之策略模式</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/05/JVM%E4%B8%AD%E7%9A%84GC%E7%AE%97%E6%B3%95/">JVM 学习（四）- GC 算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/05/JVM%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AD%98%E6%B4%BB%E5%88%A4%E6%96%AD/">JVM 学习（三）- 对象的存活判断</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/04/JVM%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/">JVM 学习（二）- 对象的访问定位</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/04/03/JVM%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/">JVM 学习（一）- 对象的内存布局</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/03/24/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95%E8%B0%83%E7%A0%94%E7%AC%94%E8%AE%B0/">分布式系统下的共识算法调研笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/03/18/%E5%8C%BA%E5%9D%97%E9%93%BE%E7%AE%80%E5%8D%95%E5%8E%9F%E7%90%86%E5%8F%8APython%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE/">区块链简单原理及Python实现简单的区块链</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/03/15/Scala%E9%87%8C%E7%9A%84%E5%9E%8B%E5%8F%98/">Scala学习笔记（十一）- Scala里的型变(Variance)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/03/15/%E2%80%9C%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%EF%BC%8C%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%EF%BC%8C%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E2%80%9D/">策略模式之简单工厂模式，工厂方法模式，抽象工厂模式</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/25/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0/">常见的排序算法实现</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/22/Johnson%E7%AE%97%E6%B3%95/">Johnson算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/20/Floyd-Warshall%E7%AE%97%E6%B3%95/">Floyd-Warshall算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/17/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E5%92%8C%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/">最短路径和矩阵乘法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/14/SPFA%E7%AE%97%E6%B3%95/">SPFA算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/13/Dijkstra%E7%AE%97%E6%B3%95/">Dijkstra算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/12/Bellman-Ford%E7%AE%97%E6%B3%95/">Bellman-Ford算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/10/Prim%E7%AE%97%E6%B3%95/">Prim算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/10/Kruskal%E7%AE%97%E6%B3%95/">Kruskal算法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/02/09/%E6%B5%85%E8%B0%88%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82/">浅谈矩阵快速幂</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/01/20/Java%E4%B8%AD%E7%94%A8Deque%E6%8E%A5%E5%8F%A3%E4%BB%A3%E6%9B%BFStack%E6%8E%A5%E5%8F%A3%E5%AE%8C%E6%88%90%E6%A0%88%E5%8A%9F%E8%83%BD/">Java中用Deque接口代替Stack接口完成栈功能</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2018/01/19/Docker%E4%B8%AD%E7%9A%84%E9%95%9C%E5%83%8F/">Docker 学习笔记（三）- Docker中的镜像</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/12/24/%E8%AF%BB%E3%80%8A%E6%9E%81%E7%AE%80%E5%AE%87%E5%AE%99%E5%8F%B2%E3%80%8B--%E6%B8%BA%E5%B0%8F%E7%9A%84%E6%88%91%E4%BB%AC%EF%BC%8C%E6%97%A0%E9%99%90%E7%9A%84%E6%80%9D%E7%BB%B4/">读《极简宇宙史》--渺小的我们，无限的思维</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/11/30/Docker%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/">Docker 学习笔记（二）- Docker基础命令</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/11/28/%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84%E9%97%AE%E9%A2%98-The-maximum-subarray-problem/">最大子数组问题(The maximum-subarray problem)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/11/23/Docker%E5%88%9D%E4%BD%93%E9%AA%8C/">Docker 学习笔记（一）- Docker初体验</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/11/12/%E5%88%A9%E7%94%A8Morris-Traversal%E6%96%B9%E6%B3%95%E9%81%8D%E5%8E%86%E4%BA%8C%E5%8F%89%E6%A0%91/">利用Morris Traversal方法遍历二叉树</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/09/11/%E5%88%A9%E7%94%A8%E7%BA%BF%E6%AE%B5%E6%A0%91%E8%A7%A3%E5%86%B3%E5%8C%BA%E9%97%B4%E6%9C%80%E5%80%BC%E6%9F%A5%E8%AF%A2-RMQ-%E9%97%AE%E9%A2%98/">利用线段树和ST算法解决区间最值查询(RMQ)问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/09/09/%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%B0%8F%E8%AE%B0/">线段树小记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/15/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E4%B8%8E%E8%B5%AB%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81-Huffman-Code/">贪心算法与赫夫曼编码(Huffman Code)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/14/Java%E9%87%8C%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%8F%8A%E5%BA%8F%E5%88%97%E5%8C%96%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/">Java里的序列化及序列化代理模式</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/14/Scala%E9%87%8C%E7%9A%84%E9%9A%90%E5%BC%8F%E7%B1%BB%E5%9E%8B%E7%BA%A6%E6%9D%9F-Implicit-Type-Bounds/">Scala学习笔记（十）- Scala里的隐式类型约束(Implicit Type Bounds)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/11/%E5%88%A9%E7%94%A8%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B3%E6%B4%BB%E5%8A%A8%E9%80%89%E6%8B%A9%E9%97%AE%E9%A2%98/">利用贪心算法解决活动选择问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/09/%E5%88%A9%E7%94%A8%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%9E%84%E9%80%A0%E9%9C%8D%E5%A4%AB%E6%9B%BC%E6%A0%91-Huffman-Tree/">利用动态规划构造霍夫曼树(Huffman Tree)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/05/Scala%E9%87%8C%E7%9A%84%E5%AD%98%E5%9C%A8%E7%B1%BB%E5%9E%8B/">Scala学习笔记（九）- Scala里的存在类型</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/04/%E5%88%A9%E7%94%A8%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%A7%A3%E5%86%B3%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97-LCS-%E9%97%AE%E9%A2%98/">利用动态规划解决最长公共子序列(LCS)问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/08/02/Scala%E4%B8%AD%E7%9A%84%E7%BB%93%E6%9E%84%E5%8C%96%E7%B1%BB%E5%9E%8B/">Scala学习笔记（八）- Scala中的结构化类型(Structural Type)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/29/%E6%B5%85%E8%B0%88Java%E4%B8%AD%E7%9A%84%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B/">浅谈Java中的枚举类型</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/27/Scala%E4%B8%AD%E7%9A%84%E8%B7%AF%E5%BE%84%E4%BE%9D%E8%B5%96%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%B1%BB%E5%9E%8B%E6%B3%A8%E5%85%A5/">Scala学习笔记（七）- Scala中的路径依赖类型(Path-dependent Type)和类型注入(Type Projection)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/27/%E5%88%A9%E7%94%A8%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%A7%A3%E5%86%B3%E7%9F%A9%E9%98%B5%E9%93%BE%E4%B9%98%E6%B3%95%E9%97%AE%E9%A2%98/">利用动态规划解决矩阵链乘法问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/26/Scala%E4%B8%AD%E7%9A%84%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%A0%94/">Scala学习笔记（六）- Scala中的隐式转换系统</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/22/%E5%88%A9%E7%94%A8%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%A7%A3%E5%86%B3%E9%92%A2%E6%9D%A1%E5%88%87%E5%89%B2%E9%97%AE%E9%A2%98/">利用动态规划解决钢条切割问题</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/09/Scala%E4%B8%AD%E7%9A%84%EF%BC%82%E8%87%B4%E5%91%BD%E9%92%BB%E7%9F%B3%E9%97%AE%E9%A2%98%EF%BC%82/">Scala学习笔记（五）- Scala中的＂致命钻石问题＂</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/08/Scala%E4%B8%AD%E5%91%BD%E5%90%8D%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E5%9D%91%EF%BC%88%E6%88%AA%E8%87%B3Scala2-12-2%EF%BC%89/">Scala学习笔记（四）- Scala中命名参数的一个小坑（截至Scala2.12.2）</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/07/%E5%B0%BE%E9%80%92%E5%BD%92%E8%B0%83%E7%A0%94%E7%AC%94%E8%AE%B0/">尾递归调研笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/07/03/Java%E4%B8%AD%E6%B6%88%E9%99%A4%E8%BF%87%E6%9C%9F%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8/">Java中消除过期的对象引用</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/06/25/%E5%9C%A8vim%E4%B8%AD%E4%BF%9D%E5%AD%98%E6%AD%A3%E5%9C%A8%E7%BC%96%E8%BE%91%E7%9A%84%E6%96%87%E4%BB%B6%E8%80%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E5%BF%85%E8%A6%81%E7%9A%84%E6%9D%83%E9%99%90/">在vim中保存正在编辑的文件而不需要必要的权限</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/06/19/Java%E4%B8%AD%E6%9E%84%E9%80%A0%E5%99%A8%E5%92%8C%E5%8D%95%E4%BE%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA/">Java中构造器和单例对象的创建</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/06/18/Java%E4%B8%AD%E9%81%BF%E5%85%8D%E5%88%9B%E5%BB%BA%E4%B8%8D%E5%BF%85%E8%A6%81%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E6%B3%95/">Java中避免创建不必要对象的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/06/08/Scala%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9B%B8%E7%AD%89%E6%80%A7%E5%B0%8F%E8%AE%B0/">Scala学习笔记（三）- Scala中对象相等性</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/05/24/Scala%E7%9A%84%E4%BC%A0%E5%80%BC%E5%92%8C%E4%BC%A0%E5%90%8D%E5%87%BD%E6%95%B0%E5%B0%8F%E8%AE%B0/">Scala学习笔记（二）- Scala的传值和传名函数</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/04/25/%E9%80%9A%E7%94%A8%E5%90%8E%E7%BC%80%E6%A0%91%E5%B9%B6%E8%A1%8C%E5%8C%96%E6%9E%84%E5%BB%BA%E7%AE%97%E6%B3%95%E6%80%9D%E8%B7%AF/">通用后缀树并行化构建算法思路</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/04/04/yum%E5%AE%89%E8%A3%85CDH-Hadoop-HA%E6%A8%A1%E5%BC%8F/">yum 安装 CDH Hadoop (HA模式)</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2017/01/03/Scala%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E7%B3%96%E5%92%8C%E7%89%B9%E6%80%A7/">Scala学习笔记（一）- Scala的一些语法糖和特性</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2016/11/22/KMP%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/">KMP算法小结</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/2016/07/30/Cpp%E4%B8%ADchar-%EF%BC%8Cconst-char-%EF%BC%8Cstring%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2/">C++ 中char*，const char*，string的相互转换</a></li></ul>




    <script>
        
    </script>

</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017-2022 Hazza Cheng
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_uv">
                      您是第 <span id="busuanzi_value_site_uv"></span> 位小伙伴
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        本站总访问量 <span id="busuanzi_value_site_pv"></span> 次
                    </span>
                
                <span>| </span>
                <span class="post-count">  已经写了 610.5k 字啦</span>
            </div>
        
        </br>
        <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
        <script>
            var now = new Date(); 
            function createtime(){ var grt= new Date("04/02/2017 11:02:49");//此处修改你的建站时间或者网站上线时间 
            now.setTime(now.getTime()+250); 
            days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
            hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
            if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
            mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
            seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
            snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
            document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
            document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; } 
            setInterval("createtime()",250);
        </script>
    </div>
</footer>

    </div>
    
    
<script src="/js/GithubRepoWidget.js"></script>


<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        $("a[target=_blank]").removeAttr("target");
    
</script>

    <script>
        var originTitle = document.title;
        var titleTime;
        document.addEventListener("visibilitychange", function() {
            if (document.hidden) {
                document.title = "(つェ⊂) 我藏好了哦~ " + originTitle;
                clearTimeout(titleTime);
            }
            else {
                document.title = "(*´∇｀*) 被你发现啦~ " + originTitle;
                titleTime = setTimeout(function() {
                    document.title = originTitle;
                }, 2000);
            }
        })
    </script>

<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  </div>
</body>
</html>